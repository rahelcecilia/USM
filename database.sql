-- phpMyAdmin SQL Dump
-- version 5.2.1
-- https://www.phpmyadmin.net/
--
-- Host: localhost:3306
-- Generation Time: Aug 24, 2023 at 06:25 PM
-- Server version: 10.3.39-MariaDB-cll-lve
-- PHP Version: 8.1.16

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
START TRANSACTION;
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Database: `rahel_usm`
--

-- --------------------------------------------------------

--
-- Table structure for table `login`
--

CREATE TABLE `login` (
  `id_user` int(11) NOT NULL,
  `name` varchar(100) NOT NULL,
  `email` varchar(100) NOT NULL,
  `role` varchar(10) NOT NULL,
  `password` varchar(50) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=latin1 COLLATE=latin1_swedish_ci;

--
-- Dumping data for table `login`
--

INSERT INTO `login` (`id_user`, `name`, `email`, `role`, `password`) VALUES
(2, 'Administrator', 'admin@gmail.com', 'Admin', '123');

-- --------------------------------------------------------

--
-- Table structure for table `project`
--

CREATE TABLE `project` (
  `id_project` int(50) NOT NULL,
  `title` text DEFAULT NULL,
  `team` text NOT NULL,
  `abstract` longtext NOT NULL,
  `background` longtext NOT NULL,
  `methods` longtext NOT NULL,
  `results` longtext NOT NULL,
  `discussion` longtext NOT NULL,
  `conclusions` longtext NOT NULL,
  `references` longtext NOT NULL,
  `keyword` text NOT NULL,
  `references2` longtext NOT NULL,
  `gambarName` varchar(25) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `project`
--

INSERT INTO `project` (`id_project`, `title`, `team`, `abstract`, `background`, `methods`, `results`, `discussion`, `conclusions`, `references`, `keyword`, `references2`, `gambarName`) VALUES
(85, 'Deep Learning Applications in Solid Waste Management: A Deep Literature Review', '<p style=\\\\\\\"text-align: center;\\\\\\\">Sana Shahab<sup>1</sup>, Mohd Anjum<sup>2</sup>, M. Sarosh Umar<sup>3</sup><br />Department of Business Administration, College of Business Administration<sup>1</sup><br />Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh 11671, Saudi Arabia<sup>1</sup><br />Department of Computer Engineering, Aligarh Muslim University, Aligarh, India2, <sup>3</sup></p>', 'Solid waste management (SWM) has recently received more attention, especially in developing countries, for smart and sustainable development. SWM system encompasses various interconnected processes which contain numerous complex operations. Recently, deep learning (DL) has attained momentum in providing alternative computational techniques to determine the solution of various SWM problems. Researchers have focused on this domain; therefore, significant research has been published, especially in the last decade. The literature shows that no study evaluates the potential of DL to solve the various SWM problems. The study performs a systematic literature review (SLR) which has complied 40 studies published between 2019 and 2021 in reputed journals and conferences. The selected research studies have implemented the various DL models and analyzed the application of DL in different SWM areas, namely waste identification and segregation and prediction of waste generation. The study has defined the systematic review protocol that comprises various criteria and a quality assessment process to select the research studies for review. The review demonstrates the comprehensive analysis of different DL models and techniques implemented in SWM. It also highlights the application domains and compares the reported performance of selected studies. Based on the reviewed work, it can be concluded that DL exhibits the plausible performance to detect and classify the different types of waste. The study also explains the deep convolutional neural network with the computational requirement and determine the research gaps with future recommendations.', 'In recent years, waste generation around the globe has\r\nincreased multi-folds due to population growth, fast urban\r\nsettlement, economic development, and advancement in\r\nlifestyle [1]. The World Bank statistics indicate that the\r\nworldwide solid waste (SW) generation was approximately\r\n2.01 billion tons per annum in 2016. It is predicted that the\r\nworld will produce 2.01 and 3.40 billion tons annually by 2030\r\nand 2050 [2]. The statistics indicate the significant increase in\r\nthe SW generation around the globe [3]. More than 33 per cent\r\nof the total generated MSW are not handled in an\r\nenvironmentally safer manner, with the waste dumped illegally\r\non roadsides or abandoned lands [2]. This poorly handled and\r\nopenly dumped waste directly affects the environment,\r\nconstitutes health risks of inhabitants, and engenders water and\r\nair pollution and land deterioration [4]. Therefore, this massive\r\nquantity of SW has become a significant threat to the\r\necosystem of the city and surrounding areas [5]. It has also\r\ngiven birth to illegal dumping [6]. It also substantially obstructs\r\nthe sustainable growth of the city/region [7]. Nowadays,\r\ncountries are more serious about a healthier and more\r\nsustainable environment. Several studies evidence that the\r\nleading causes of poor SWM are inadequate planning and\r\nimproper operations [8], [9]. SWM bodies lack funds,\r\ninfrastructure, and advanced technology in most developing\r\ncountries. After the emergence of smart cities and sustainable\r\nurban development, researchers have put a lot of effort into\r\ntransforming the SWM industry using current technologies and\r\nintelligent systems [10]. SW is a natural product from daily life\r\nactivities and per capita waste generation significantly more in\r\nurban regions than rural areas due to high income and urban\r\nlifestyle [11]. SWM has emerged as a crucial environmental\r\nissue around the globe, especially in developing countries [12],\r\n[13]. Therefore, it is strongly demanded to create an effective\r\nSWM system for conserving resources protecting\r\nenvironmental and public health [14]. The environ=mental\r\nproblems of SWM are very complex to resolve because of their\r\nheterogeneous nature [15].\r\nThe background analysis concludes that the SWM has\r\nfocused on utilizing cutting-edge technologies to improve and\r\nautomate the services. Advanced technologies such as the\r\ninternet of things (IoT), information technology, machine\r\nlearning (ML) have drastically improved the efficiency of\r\nvarious SWM processes, namely waste forecasting, collection,\r\ntransportation, sorting and recycling [16], [17]. DL subset of\r\nML methods has been significantly implemented in diverse\r\nareas of the environment, such as pollution control,\r\nwastewater, SWM services [18]. The SWM system\r\nencompasses various interconnected processes which contain\r\nnumerous complex operations. This system also involves many\r\nnon-linear parameters, including highly inconstant influencing\r\nfactors, namely socioeconomic and demographic [19]. It is\r\nchallenging to optimize the performance of these systems\r\nwithout affecting the health of inhabitants and the environment\r\n[20]. Therefore, DL techniques are supposed to involve in all\r\nstages of the SWM system. In earlier review studies, Ye et al.\r\n(2020) has thoroughly analyzed the 85 papers published in\r\n2004 - 2019 and demonstrated the different applications of\r\nartificial intelligence (AI) models in the SWM service\r\nframework. In [21], the author has reviewed approximately 200\r\nstudies published during the last two decades and summarized\r\nthe applications of ML methods in different stages of SWM\r\nfrom waste inception to final disposal. In parallel with these\r\nextensive studies, this SLR study primarily concentrates on the applications of DL models in SWM services and interpret it in\r\nview of overall process of SWM.\r\nThe main goal of this SLR study is to motivate the\r\nresearchers more to apply DL techniques for solving various\r\nSWM problems involving waste detection, classification,\r\nprediction etc. It compares the performance of DL models and\r\nuncovers the best models for different tasks. It also highlights\r\nsome gaps in applications of DL for SWM tasks and discusses\r\nsome aspects for future priority. This information will help the\r\nresearchers to choose the better model for their studies. The\r\noverall benefits of DL are encouraging for its further use\r\ntowards developing an innovative and sustainable SWM\r\nsystem.\r\nThe survey study is structured in the following sections.\r\nSection II draws the picture of applications of various DL\r\nmodels in SWM. Section III comprises the methodology of the\r\nSLR architecture, which involves systematic review protocol,\r\nreview questions, searching process and selection criteria,\r\nscreening, article quality assessment, and data extraction.\r\nSection IV explains the overview of survey findings which\r\nincludes descriptive statistics of review: country of the author\r\nacademicÃ¢â‚¬â„¢s affiliation, mainstream journals and their\r\npublishing areas, and thematic analysis: major DL models,\r\ntheir applications, data set used, performance evaluation and\r\ncomparison with other DL/conventional method, and depicts\r\nthe detail description of CNN models. Section V illustrates the\r\nconcept of DL, the design of a CNN architecture and\r\ncomputational requirements to implement the CNN models.\r\nSection VI identifies the Research gaps and priorities,\r\ndemonstrating data acquisition, data preprocessing, model\r\nselection and architecture definition, and model comparison.\r\nSection VII comprises the summary of the SLR, important\r\nobservations with shortcomings and the reason for the\r\npopularity of DL in SWM. Finally, the conclusion of the SLR\r\nstudy is displayed in Section VIII.', '<p><strong>II. SKETCH OF DL IN CONTEXT OF SWM</strong></p>\r\n<p>The literature demonstrates that emerging DL models can be effectively applied in the SWM field [17]. DL is a large subset of ML techniques that comprises various computational methods and algorithms that implements artificial neural networks (ANN) with feature learning. DL techniques have significantly transformed the field of computer vision and image processing. Therefore, DL has emerged as the most attention-drawing branch of ML in recent years and has gradually reached the top. The convolutional neural network (CNN) is an epoch-making category of deep neural networks with huge potential and tremendous image recognition growth with reliable outcomes. CNN can be recognized as fundamental building blocks in diverse tasks such as photo tagging, medical imaging, and self-driving cars. A typical workflow of the DL models is depicted in Fig. 1. Generally, it comprises four main steps: (1) Data collection and preparation (2) Choosing or designing model and hyperparameters (3) Training, testing, and performance evaluation (4) Tuning hyperparameters if needed and deployment. Table VII lists the DL models applied in the SWM with research objectives/goals.</p>\r\n<p>They are also exhibiting significant growth in everything from security to environment and waste management. Many eminent researchers around the globe have made remarkable contributions in SWM using DL. In SWM, DL models have been extensively implemented to solve various problems such as waste identification and segregation, real-time bin level detection, and prediction of waste generation. DL models have abilities to recognize and learn features directly from the image. This distinct feature has substantially enhanced image detection and classification. The transfer learning technique is implemented using a combination of three pre-existing CNNs, namely VGG19, DenseNet169, and NASNetLarge, to classify the waste into six categories [22]. Many CNN architectures have been proposed with different layers to categorize the different types of waste, such as recyclable: metal, paper, plastic, cardboard, nonrecyclable, medical, biodegradable, inorganic, trash, etc. [23], [24].</p>\r\n<p>The pre-existing CNNs, namely enhanced ResNext [25], YOLOv2 and YOLOv3 [26], ResNet-50 and Auto Encoder network with support vector machine as classifier [27], [28], MobileNet-V2 [29] and Hybrid of CNN and multilayer perceptron [30] have also been performed above type classification tasks. Waste classification is an important activity to separate different types of waste, which significantly improves the recycling efficiency of the process. Various types of CNN with different layers have also been substantially used in many tasks of SWM other than waste detection and classification. A Long Short Term Memory (LSTM) CNN has been implemented to predict the amount of waste generation [31], [32], and carbon dioxide concentration in the waste bin [33]. Additionally, a deep CNN has been designed that consider various waste generation influencing factors to forecast the per capita waste generation [34] and demolition waste for three categories reusable, recyclable, and landfill [35]. A waste bin equipped with a camera, microcontroller, and servo motor has been built to separate the different types of waste materials automatically. The hardware of the bin is controlled by custom software based on the ResNet-34 algorithm with multi-feature fusion and a new activation function [17], [36].</p>\r\n<p>Moreover, different CNN models have been implemented to identify and locate the illegal dumps using street-level image data and high-resolution satellite imagery [37], [38]. Based on the analysis of selected research papers for SLR, DL models have been extensively utilized in SWM, from waste inception to final disposal. They have been implemented in SWM processes such as waste generation prediction, bin level detection, material identification, illegal dump detection and location identification, and waste classification (refer to Tables VII and VIII). This can help to develop sustainable SWM service infrastructure through efficient resource utilization. DL has significantly impacted the recycling process as it has the power to detect different types of material and items to segregate. This has made the recycling process very effective and efficient in material recovery. Fig. 2 displays the application of the DL models in different stages of the SWM processes.</p>\r\n\r\n<p>To explore the potential applications of various CNNs models to provide the effective and efficient solution of different tasks involved in SWM, a thorough analysis of recently published studies is necessary to increase more advanced developments in this field. The survey demonstrates the comprehensive SLR and elaborates the various DL models implemented to enhance existing SWM techniques involved in its distinct stages, from inception to the final disposal. Some hybrid DL based approaches and performance comparison of implemented DL models with other DL/conventional models are explained to present an in-depth understanding of different models. The review study aims to provide SWM, and allied researchers are keen to apply DL approaches in their respective areas of study using major research aspects such as DL models, applications, efficiency, and accuracy. The major contribution of the survey study is to add the SLR of applications of DL in SWM, which was not previously figured out in the knowledge pool of existing literature.</p>\r\n<p><strong>III. METHODOLOGY</strong></p>\r\n<p>An SLR is carried out to examine the application of DL in SWM research published from 2019 to 2021. The SLR is defined as a systematic procedure to summarize the experimental results of the studies related to an investigation or technology, determine the gaps in current research, and develop the background for new research. The content of SLR is motivated and structured according to two systematic review studies, namely, [39], [40]. The SLR presents a comprehensible view of various DL techniques implemented in SWM. Following typical steps are conducted to enhance the creditability and reliability of the review.</p>\r\n<p><strong><em>A. Systematic Review Protocol</em></strong></p>\r\n<p>The SLR is performed to identify, evaluate, and interpret potential studies applying DL models in various SWM domains [40]. The study extensively follows the SLR methodology, which provides equitable review procedures, ensures quality to credibility, and understands results and conclusions. The SLR has a standard protocol comprising three phases: planning, execution, and reporting [40], [41]. The systematic review protocol defines the methodology of locating, studying, analyzing, and evaluating the research articles. Fig. 3 demonstrates the proposed review prototype based on the SLR guidelines. The SLR protocol describes the review process and is generally explained in technical reports.</p>\r\n\r\n<p><em><strong>B. Review Questions</strong></em></p>\r\n<p>The primary objective of the SLR is to recognize and assess the published literature that implements the DL model in SWM. The following typical review questions are formulated and addressed to execute the proposed methodology. <br />RQ1: What are the different applications of the DL model in SWM? <br />RQ2: What are the DL models implemented to solve SWM problems? <br />RQ3: How is the performance of different models with respect to other algorithms and techniques?</p>\r\n<p><strong><em>C. Searching Process and Selection Criteria</em></strong></p>\r\n<p>The methodology considers an individual research paper or article as a review unit, called a document. All the documents are retrieved from a global digital libraries database, namely Scopus, Elsevier, Google Scholar, Springer, IEEE, Wiley, Emerald, and Web of Science. These are the top libraries that contain peer-reviewed global research from multiple disciplines and are widely accessed by authors to perform SLR. The preliminary search retrieved numerous articles associated with the SWM, DL and CNN but did not exhibit the direct implementation of the DL model in SWM. Additionally, many publications were also in top search, applying the conventional model (such as statistical model) in SWM. This initial search retrieved approximately 550 documents from 2019 to 2021 from the digital search libraries. Then, structured query searches with inclusion and exclusion criteria were executed to retrieve relevant literature and restrict the number of documents. These search queries included some keywords for accepting and rejecting the documents [42]. In SLR, the application of DL was the main keyword, and SWM was the context in the query string. Therefore, all searched queries were around two aspects, (a) application of DL (b) context: SWM. Table I depicts the matrix of retrieved documents for chosen keywords from afore mentioned digital libraries.</p>\r\n\r\n<p>Additionally, the inclusion keywords were &ldquo;waste management&rdquo;, &ldquo;garbage&rdquo;, &ldquo;litter&rdquo;, &ldquo;trash&rdquo;, &ldquo;dump&rdquo;, &ldquo;rubbish&rdquo;, &ldquo;deep learning&rdquo;, &ldquo;convolutional neural network&rdquo;, and &ldquo;deep neural network&rdquo; while exclusion keywords were &ldquo;waste recycling&rdquo;, &ldquo;wastewater treatment&rdquo;, &ldquo;waste-to-energy&rdquo;, &ldquo;sewer systems&rdquo;, &ldquo;waste incineration&rdquo;, and &ldquo;vehicle routing&rdquo;. The gathered literature was analyzed and evaluated in a methodology context covering the studies that implemented the DL techniques to address the SWM issues. After executing the search as mentioned above procedure, 105 studies were uncovered as pertinent to the search topic for 2019-2021.</p>\r\n<p><strong><em>D. Screening Manual</em></strong></p>\r\n<p>scrutiny was carried out to ensure the completeness, reliability, and quality of SLR. Inclusion and exclusion criteria were set to make the scrutiny process straightforward, manageable, and objective. Table II displays the chosen inclusion and exclusion criteria to select the papers under four categories for further review. These categories were publication type, document language, accessibility, and subject/title. Then, all selected documents in the searching and data collection process were reviewed according to the attributes set in Table II. The journal or conference research was selected in the first screening, completely accessible and available in English. Generally, conference papers lack quality; therefore, their use in SLRs is uncommon [43]. But few good qualities conference papers were considered in the study. Moreover, their title / subject was also analyzed to determine and choose the most competent research.</p>\r\n\r\n<p>Additionally, the abstract and conclusion were also rigorously inspected and analyzed in the context of the search topic to determine the more suitable papers and eliminate the duplicate documents having different titles but identical content. It was also investigated that the selected documents were concentrated on applying DL models in the context of SWM. After accomplishing the entire screening process, 65 studies out of 105 were promoted for further process.</p>\r\n<p><strong><em>E. Quality Assessment</em></strong></p>\r\n<p>After conducting the screening process, a quality check was performed for all selected studies. The quality assessment checklist was formulated to assess individual research and prune the insignificant and irrelevant research [40]. Ten quality criteria were determined to develop the checklist, and each study was evaluated qualitatively. A questionnaire was formulated to represent the criteria in the form of questions answered on the Likert scale of 5. The Likert scale and designed questions are presented in Table III and Table IV. The overall score of each paper was calculated by adding the points achieved in all questions stated in Table IV. The article was chosen for review if it had an overall score of more than or equal to 25 points. The top 40 papers out of 105 were picked after performing the quality assessment process.</p>\r\n<p><strong><em>F. Data Extraction</em></strong></p>\r\n<p>The pertinent data is extracted from all selected studies and summarized in Tables VI and VII to determine the consolidated outcomes. This extracted data includes the items, namely implemented DL model/technique, study goal/objective, key findings, application domains, dataset utilized in model evaluation, and performance comparison with other benchmark studies.</p>\r\n\r\n', '<p><strong>IV. OVERVIEW OF SURVEY FINDINGS</strong></p>\r\n<p><strong><em>A. Descriptive Statistics of Review</em></strong></p>\r\n<p>In the SLR study, 40 research studies were considered published globally in the recent three years, i.e., 2019(7), 2020(22) and 2021(11). All the studies were reviewed according to the country of the academic&rsquo;s affiliation to analyze the contribution of various regions in the subject area. Asia published the most significant number of studies that focused on the review subject area (57.5%), and most of these studies were performed in China (22.5%). 35 % of total studies were contributed from the European region, and 7.5% were from Australia and Africa. Researchers from developing countries conducted 60% of the total studies. At the same time, the remaining 40% belonged to the developed countries, with the categorization of developing/developed countries according to the Human Development Report [44]. The statistics exhibited that researchers from developing countries focused more on SWM than developed countries. The literature evidenced that SWM was a crucial problem in developing countries; therefore, authors gave more attention to SWM research and published more studies. Motivated by the SLR study in [45], all the selected studies were analyzed by publication to determine the mainstream journals and their publishing areas. Table V depicts the list of journals and conferences. The best journals of studies subject with documents count were IEEE Access (5) and Waste Management (5). These results concluded that electronics and computer science researchers focused on applying the current state of the art of their field and invested more effort to solve the SWM issues by developing automatic and intelligent systems. Additionally, Waste Management was dedicated to SW Management, Disposal, Policy, Education, Economic and Environmental assessment. According to the analysis of publishing areas of each journal, it was deduced that SWM research was strongly related to the environmental sciences.</p>\r\n<p><strong><em>B. Thematic Analysis of Review</em></strong></p>\r\n<p>After the emergence of the various computational model of DL, no review study consolidated the applications of DL models in SWM and allied fields. The analysis of compiled studies unveiled four major applications of DL in SWM, namely waste detection, identification, bin level detection, and forecasting of waste generation. Additionally, DL was also applied to perform tasks such as demolish material prediction, custom software development for robot control, defect detection in potatoes, and different types of polythene material. Table VI displays the applications of DL models identified in considered studies and implemented model performance evaluation for the used data set. All the studies except one had applied the proposed model on an actual data set which showed the experimental performance of the models. Only one study had performed the experiments on simulated data to evaluate the model performance. A significant number of studies had compared the performance of the implemented model with other DL/conventional models. Moreover, most studies had a sufficiently large data set to train, validate and test the proposed model. Therefore, it could be concluded that the performance of the models was reliable and could be utilized for comparison in further studies.</p>\r\n\r\n<p>Table VII demonstrates the proposed DL models, objectives, and key results of compiled studies. A significant number of studies had implemented pre-existing CNN for selfconstructed data set. In contrast, the remaining studies had designed their own CNN and applied it to their data set to demonstrate the experimental results. The deeper analysis of compiled studies deduced that most studies concentrated on the different waste identification and classification types. At the same time, some focused on the prediction of waste generation with various influencing factors. Few studies developed the smart bin using the IoT, and the DL model was used to build the custom software to control the bin hardware. One study constructed the waste picking robot from the grass ground, using DL-based custom software to manage the robot hardware. Moreover, objectives such as detecting different types of polythene materials and defects in potatoes were also obtained successfully. The key results of complied studies are discussed in detection precision and classification accuracy. The evaluation of results exhibits that the reported accuracies were more than 90%.</p>\r\n<p>The comprehensive analysis of considered studies indicates that a significant number of studies had implemented preexisting CNNs such as AlexNet, MobileNet-v2, YOLOv3, ResNet-50, NASNetLarge while remaining studies applied manually constructed CNNs which are built through a different number of neural layers. Pre-existing CNNs are developed by various researchers from academic and industry backgrounds. The CNNs have already demonstrated remarkable performance on image recognition benchmarks. These networks are trained, so only top layers, called fully connected layers, are retrained and fine-tuned according to the data set. Conceptually, these networks reutilize the weights and structure of a prior model from the convolutional layers. The construction and training of a CNN based new image recognition from scratch involve a lot of time and computational power. Therefore, the utilization of pre-existing networks increases computational efficiency.</p>\r\n<p><strong>V. DEEP LEARNING</strong></p>\r\n<p>In the last decade, AI has completely transformed and shifted into the era of computation, and DL is the only reason for this cutting-edge development. It has a very interesting and unique feature to &lsquo;self-learn&rsquo; distinctive patterns directly from the data. It has the ability to extract features automatically without hand crafting them. It has emerged as the most promising computing method to automate the categorization of visual and spatial data in the context of SWM. Nowadays, SWM and allied field researchers are getting huge amounts of street or city-level data from various systems such as city surveillance systems, unmanned aerial vehicles, highresolution satellite imagery, or online platforms where many people participate in data collection [67]. However, conventional AI methods have limited capacity to analyze this huge amount of data which is a bottleneck for researchers [68]. DL computing techniques have the extensive power to overcome this condition through automatic analysis of a massive dataset.</p>\r\n<p>DL theoretical concepts are not developed recently; it has been published as far back as the 1980s [69]. This approach has become more prevalent, understandable, and practically possible in the last decade due to tremendous growth in computer hardware, the development of exceptional computational tools, and the accessibility of massive preprocessed and annotated data necessary to implement this methodology [70]. The literature analysis evidence that it has been implemented in automation of complex data computation tasks, object detection and location in visual data, photo tagging, self-driving car, speech recognition etc., across a wide range of industries [70]. The authors strongly believed that this methodology could achieve similar remarkable advantages in SWM. It potentially saves a lot of time for manual data analysis; therefore, DL enables the SWM and allied researchers to concentrate on more crucial tasks and could develop improved features for large scale and real-time monitoring SWM systems [16], [17].</p>\r\n<p>A subset of ML, DL consists of utilizing the data structures named &lsquo;deep ANN&rsquo;, interchangeably DL. It is fundamentally consecutive arrangements of non-linear functions or several layers of digital neurons. These multiple layers of neurons construct the deeper the network. These networks learn hidden patterns automatically from the input data without explicit construction of distinct features to categorize the data. This drives the AI to be widely understandable and usable to nonexpert users. DL models are trained to perceive and learn these patterns by labelled inputs and corresponding outputs. After learning, the model predicts data that was never seen earlier [70]. This AI model, where labelled data is given in training of deep ANN, is termed supervised DL. Fig. 4 displays DL workflow using supervised learning through classification of e-waste items.</p>\r\n\r\n<p><strong><em>A. Convolutional Neural Network </em></strong></p>\r\n<p>The CNN is an essential class of deep neural networks, more precisely, DL, a subset of ML and inherently re-branding ANN. CNN has exhibited massive growth in image recognition, so they are specially implemented to analyze visual data and perform tasks beyond classification. The CNN allows to extract the features from the image and conducts its training from these features. It is different from a conventional neural network in processing and extracting features. Image features are handcrafted to implement image recognition using a conventional neural network while CNN receives the image&rsquo;s raw pixels as input data, trains the proposed model, then automatically extracts the features to perform the better classification. Fig. 4 depicts the general architecture of a CNN [71]. A typical CNN has comprised an input layer, followed by the alternate combination of convolutional and pooling layer, and top of the network fully connected layer followed by classification output layer.</p>\r\n<p>&nbsp;The input layer defines the size of the input image and holds the values of raw pixels extracted from the image. The input image dimensions are represented by the height, width, and the number of colour channels (1 and 3 for grayscale and colour images, respectively) in the image. This layer also carries out input data preprocessing such as simple rescaling or normalization, mean subtraction, normalization and principal component analysis and whitening.</p>\r\n<p>The convolution layer is the core element of CNN building which comprises filter and stride. A filter is a small size twodimensional layer of neurons mapped over a small segment of the input image and covers the whole image through shifting. The convolution operation is performed by the computing dot product between the filter and image pixel, added over the filter area. After that, the filter is shifted in the horizontal and vertical direction to perform similar computation in each area of the whole image. The step size of shifting is called stride. When the filter moves over the input image or output of the preceding layer, it uses the same set of weights to carry out the convolution operation to create the feature maps. Therefore, feature maps and filters are equal in number. All feature maps comprise a different set of weights and neurons of the same map using similar weights for different input regions. Initially, all these filters have random values and become network parameters that will be learned subsequently.</p>\r\n<p>The pooling layer decreases output data size from the convolution layer, called down sampling operation. Various types of pooling functions occur, but max pooling is generally utilized. It reduces the count of connections to the following layer, the typically fully connected layer. It also decreases the count of parameters learnt in the previous layer and does not perform any learning. The max-pooling filter gives the maximum value for every sub-region.</p>\r\n<p>A fully connected layer is called a hidden layer, like an ANN. It connects each neuron of the preceding layer with every neuron of the successive layer. It determines the patterns to categorize the images by incorporating the features learned in the preceding layers and usually learns the non-linear function.</p>\r\n<p><strong><em>B. Computational Requirements</em></strong></p>\r\n<p>Generally, deep CNN models are implemented in several programming languages: Python, R, MATLAB, Java, and C/C++. Many open-source software libraries such as TensorFlow, PyTorch, OpenCV, Theano and Microsoft CNTK (Cognitive Toolkit) provide a diverse range of functions for most of the programming languages, including Python and R [72][73]. Moreover, software libraries like Keras provide a highly simplified interface for the DL libraries like TensorFlow.</p>\r\n<p>The physical resources required to execute DL models are either Graphical Processing Unit (GPU) or Central Processing Unit (CPU). Generally, a CPU comprises only 2 to 16 cores, which are the smallest computation unit in a computer. A GPU consists of thousands of more simplified cores than CPU cores, optimized to execute parallel arithmetic operations, and is best for executing DL models [74]. Therefore, GPU decreases the program execution time in significant orders of magnitude and makes physical implementation possible [70]. Nowadays, an alternative is available for computation, which does not need the local computer hardware resources, is called cloud computing. It provides online on-demand computing and storage resources for computation without user management. Platforms like Google Cloud Platform Microsoft Azure provide a subscription to execute DL models online at cloud.</p>\r\n<p><strong>VI. RESEARCH GAPS AND PRIORITIES</strong></p>\r\n<p>&nbsp;Even though DL models have been extensively implemented in recent years to solve various SWM problems, they are still in the early phase of evolution and application. This SLR study has uncovered some gaps in applying DL models to SWM, and some aspects must be prioritized in the future.</p>\r\n<p><strong><em>A. Data Acquisition </em></strong></p>\r\n<p>DL models perceive insights and uncover hidden patterns from a massive amount of data applying various techniques. Reliable and enough data are the most fundamental and core elements of DL models applications. The quality and quantity of historical waste data are extremely crucial for the reliable performance of the DL model [75]. However, most of the studies deal with small or medium datasets, which could be attributed to SWM infrastructure and practices [16], [47]. Generally, SWM associated data are collected and organized by distinct channels encompassing various stakeholders. This hybrid management structure makes the data gathering and compilation extremely hard and complex [76]. Due to the lack of SWM related data, precise DL models are tough to implement. Furthermore, authors have analyzed that most research studies have utilized self-constructed data set for training, validation, and testing purposes. Therefore, it implies that the data set for DL model implementation is not available in the public domain. The scarcity of open benchmark data set is a major obstacle in implementing DL models in SWM and allied fields.</p>\r\n<p>&nbsp;Now-a-days, many techniques are available to construct a large data set from a smaller one. For example, data augmentation is one of the most prevalent methods in fields such as data analysis to increase data size for effective and accurate model implementation. In SWM tasks such as waste classification material detection, the data augmentation technique is utilized to increase the amount of sample data for better performance of the DL model [52], [64]. Additionally, the collection of waste generation data is growing due to extensive waste monitoring, and some constructive data set are accessible freely [77]. Currently, city monitoring data is collected using remote sensing, geographic information system, unmanned aerial vehicle photography, satellite imagery, and modern technologies like IoT, sensors, and radio frequency identification to develop the SWM monitoring system. These sources generate a massive amount of data; therefore, it is highly demanded to develop a system for combining these existing data resources and constructing a data management platform with a unified protocol for distinct formats and types. Data fusion technology can also be applied to analyze and monitor the interconnection between distinct systems, databases and data types. Furthermore, data sharing mechanisms must be flexible and open to develop the reliable and quality data opening environment.</p>\r\n<p><em><strong>B. Data Preprocessing</strong></em></p>\r\n<p>&nbsp;Data preprocessing is not a vital phase for the AI, ML and DL models, but it is the highly consequential phase. If the collected data are processed correctly, it significantly impacts the training phase and predicted outcomes. Generally, it decreases the training time of DL model and sometimes enhances the model performance. Besides this, it is also instrumental in transforming the collected data into an appropriate form for the subsequent model phases. Missing values and noise are common in data collection and recording. Mostly linear interpolation or mean value replacement are applied to fix missing data points [31], [78]. But these methods have one major drawback of information loss. In [79], the author applied the ANN to reconstruct the missing values in methane generation data and showed a significant decrease in mean square error. This leads to the novel direction for constructing MSW data missing value to future researchers.</p>\r\n<p>&nbsp;In addition, the selection of suitable input variables for the DL model can extensively control the performance of the training phase and the robustness of DL models. These appropriate variables would improve the performance and reduce the modelling complexity. The SWM system is very complex contains various interconnected processes with numerous complex operations. This system also involves many non-linear parameters, including highly inconstant influencing factors, namely socioeconomic and demographic and operating control parameters [80]. The labelling of visual data is also highly consequential on supervised DL model learning performance and predicted results. An inaccurate label can significantly confuse the model learning, which will lead to erroneous results [81]. The survey analysis has uncovered that most of the existing studies have applied the DL algorithm on a selected set of labelled data that is correct in real-world applications. Furthermore, precise data labelling is cumbersome and time-consuming [81]. In [81], the author has demonstrated a DL technique to select the most appropriate data for labelling cost-effectively. This active labelling of data can focus on attaining the best training and testing performance for waste classification and illegal dump detection using the DL model with limited data. This can also be used to create the benchmark data set for different categories of waste.</p>\r\n<p><strong><em>C. Model Selection and Architecture Definition</em></strong></p>\r\n<p>&nbsp;Now-a-days, numerous DL models are available for implementation, but there is no specific rule to choose the best model. Generally, CNNs are applied to imagery or spatially related data, while LSTM/RNN are performed best on sequential data. Table VIII demonstrates the strengths and drawbacks of the DL models used in SWM and can help select the appropriate model. The DL model selection in SWM depends on the types of input data and tasks performed. The right accuracy selection also plays a crucial role in choosing a suitable DL model. Defining DL model architecture is a critical step for successfully executing model over studies data set with acceptable accuracy. There is no clear set of instructions to build the model, but the following two things help to develop model architecture. The model must possess satisfactory accuracy on the studies data set and must be easily retrainable or exist as a pre-trained model. The practical aspect associated with accuracy is the speed versus accuracy tradeoff. DL communities have currently constructed a diverse range of architectures for distinct use cases that can be applied in realworld problems. For example, if someone has a constraint of computing resources, then one must choose fast architecture such as MobileNetv2 [29], [55], [66], and if someone does not have the above constraint, then one can go state-of-art model which promises then best accuracy. Furthermore, some architectures are lighter and faster as they cut down the layers, making them faster and slimmer.</p>\r\n<p>Additionally, different existing or pre-trained models can be applied to the same data set to obtain the best model to perform the target task. Based on Table VI and Table VII, CNNs have been widely applied in waste classification with<br />remarkable accuracy [28]. However, these are rarely implemented in other SWM processes. Therefore, researchers have opportunities to develop new CNN architectures or can apply existing CNN in other processes. LSTM/RNN models have been implemented to forecast waste generation, but these models can have potential applications in other sequential data related to SWM [31]&ndash;[33].</p>\r\n\r\n<p><strong><em>D. Model Comparison</em></strong></p>\r\n<p>&nbsp;It must be conducted to evaluate the effectiveness and performance of the DL model. This SLR analysis has uncovered that many studies have applied on one model with showing any comparative performance with other model [27], [33], [61]&ndash;[63], [34], [35], [38], [47], [48], [50], [51], [56]. In some studies, the outcomes from different models have been compared and analyzed to choose the best one while they lack in comparison to similar models from different studies [24], [26], [31], [32]. However, these studies have shown good results, but this comparison does not provide evidence for the best model selection. Very few studies have utilized the results of other studies as a baseline for comparison, but both results are Computer using the different data set; therefore, this type of comparison does not seem very meaningful and convincing [15], [28]. In waste classification and similar tasks, a significant number of studies have demonstrated the comparison with a similar type of model on the same data set and shown better accuracy (refer to Table VI). This SLR has also undermined that the current studies do not explain more about the model description, such as hyperparameters setting and fine-tuning. Therefore, it is extremely difficult to reproduce the results from implemented DL model. Consequently, the author has suggested explaining the DL model description with minor detail that will help advance scientific research with previous outcomes and fast development and applications in SWM.</p>', '<p>The overall discussion about the SLR study can be partitioned into three subsets. The first subset describes the summary of the study. The second subset discusses an important observation with a shortcoming. The third subset explains why applications of DL models in SWM is growing with remarkable momentum.</p>\r\n<p>First, the comprehensive SLR concentrates on analyzing and evaluating the various DL models and their applications in SWM, obtained from 40 research studies published in reputed journals and reliable conferences between 2019 and 2021. The reported key results of all complied studies are displayed, and performance comparisons shown within the study are also manifested. The outcomes of the SLR study indicates that various types of CNNs, manually constructed, pre-existing, and hybrid with other approaches, have been implemented to perform various tasks. Generally, waste identification and classification problems are fundamentally complex as waste have ill-defined features readable to the machine. Therefore, traditional ML and image process algorithms do not have sufficient capabilities to provide a reasonable solution in terms of effectiveness and efficiency. Other than waste classification, DL models have also been applied to predict waste generation, gas concentration and illegal waste dump detection.</p>\r\n<p>Second, the in-depth analysis of the literature unveils that all the studies used self-constructed data set. Therefore, it can be confidently concluded that no benchmark data set exists, which is a major drawback for the researchers comparing their model performance with benchmark results. So, firstly it can be strongly recommended that an annotated benchmark data set be constructed for each waste category for future research. Secondly, it also seems clear that DL models provide more cutting-edge techniques in SWM, which are significantly effective and efficient compared to traditional ML and image process approaches. Therefore, DL models have gained sufficient momentum in the SWM research community to solve a wide variety of problems.</p>\r\n<p>Third, the field of DL has got popular recently, so researchers from SWM research communities are increasing interest in applying DL models for SWM services. The SLR evidence that applications of DL models in SWM have started recently, especially in the last three years. The literature in this field is growing at a significant pace with novel applications in different SWM tasks. Therefore, the SLR study has focused on the research published in the last three years. The maturity of DL applications in this field can take a long time as the SWM system has highly complex interconnected components. It has been practically applied in many applications, namely intelligent waste identification and classification. For example, SpotGarbage, an Android App and robot for waste picking over grass, has successfully applied the DL models to detect, localize, and classify the waste automatically. Furthermore, most of the chosen studies for SLR are exploratory, so it can also be anticipated that more applications will be in practice soon.</p>', '\r\n<p>Various AI and image processing approaches have been implemented for solving the SWM problems, such as waste generation prediction and waste level detection in the bin over the years. But in the last decade, DL has been successfully applied in diverse domains. Even though the main focus of DL (especially unsupervised learning) is in the image processing domain, this study has performed the SLR of the emerging research relating to the DL applications in the SWM. Furthermore, these approaches are popularly known to conquer the vanishing gradient problem, which was an acute limitation on the depth of ANN. In the last few years, lots of research efforts have been made to apply DL in the SWM domain. This study performs an SLR of published research that applies the DL models for SWM. Forty relevant research studies are uncovered after executing the rigorous SLR procedure. These research studies are analyzed and examined based on the SWM problem they focused, type of data set utilized, implemented models comparison, and performance evaluation according to the performance matrices used by individual papers. The performance of DL models is compared with other existing techniques. The overview of findings implies that DL exhibits better performance and outperforms as compared to other prevalent ML and image processing techniques.</p>\r\n<p>Significance of this SLR: The identified DL learning techniques have been effectively applied to model the complex processes in SWM. Therefore, DL is drawing the attention of researchers from around the world and has emerged as a foundation for SWM problem-solving. This SLR study also provides evidence that DL in SWM is the most active research field. Furthermore, it is observed that DL models consist of cutting-edge techniques to solve the SWM problems. These techniques are remarkably efficient and do not need hand crafted features as traditional ML and image process approaches. Hence, DL models have obtained significant popularity in the SWM research community to solve a wide range of problems. The main goal and significance of this SLR provide the background about different DL models with their performance in a variety of SWM tasks and gaps for future research on this particular topic. It also elaborates the basic DL model (CNN architecture) design and provides comprehensive information about DL in SWM, which could be highly useful to SWM practitioners.</p>\r\n<p>For future work, it is recommended to implement the general concepts and best practices of DL, as illustrated through this SLR, to problems of SWM where this cutting edge approach has not yet been significantly applied. One crucial suggestion is to construct the annotated benchmark data set for public use. It is strongly needed to compare and enhance the performance of the DL models. It will also provide a boost to the applications of models in SWM.</p>', '<h4>REFERENCES</h4>\r\n<p>[1] C. Mukherjee, J. Denney, E. G. Mbonimpa, J. Slagley, and R. Bhowmik, &ldquo;A review on municipal solid waste-to-energy trends in the USA,&rdquo; Renewable and Sustainable Energy Reviews, vol. 119. Elsevier, Mar. 01, 2020, doi: 10.1016/j.rser.2019.109512.</p>\r\n<p>[2] S. Kaza, L. C. Yao, P. Bhada-Tata, and F. Van Woerden, What a Waste 2.0: A Global Snapshot of Solid Waste Management to 2050, vol. 1. Washington: World Bank Publications, The World Bank Group, 1818 H Street NW, Washington, DC 20433, 2018.</p>\r\n<p>[3] C. Magazzino, M. Mele, and N. Schneider, &ldquo;The relationship between municipal solid waste and greenhouse gas emissions: Evidence from Switzerland,&rdquo; Waste Manag., vol. 113, pp. 508&ndash;520, Jul. 2020, doi: 10.1016/j.wasman.2020.05.033.</p>\r\n<p>[4] M. Triassi, R. Alfano, M. Illario, A. Nardone, O. Caporale, and P. Montuori, &ldquo;Environmental pollution from illegal waste disposal and health effects: A review on the &lsquo;triangle of death,&rsquo;&rdquo; Int. J. Environ. Res. Public Health, vol. 12, no. 2, pp. 1216&ndash;1236, Jan. 2015, doi: 10.3390/ijerph120201216.</p>\r\n<p>[5] D. Demirbilek, A. &Ouml;zt&uuml;fek&ccedil;i &Ouml;nal, V. Demir, G. Uslu, and H. Arslanoglu-IsÃ„Â±k, &ldquo;Characterization and pollution potential assessment of Tunceli, Turkey municipal solid waste open dumping site leachates,&rdquo; Environ. Monit. Assess., vol. 185, no. 11, pp. 9435&ndash;9449, 2013, doi: 10.1007/s10661-013-3263-7.</p>\r\n<p>[6] D. H. F. da Paz, K. P. V. Lafayette, M. J. de O. Holanda, M. do C. M.Soal, and L. A. R. de C. Costa, &ldquo;Assessment of environmental impactrisks arising from the illegal dumping of construction waste in azil,&rdquo;Environ. Dev. Sustain., vol. 22, no. 3, pp. 2289&ndash;2304, Mar. 2020, doi:10.1007/s10668-018-0289-6.</p>\r\n<p>[7] A. S. Nagpure, &ldquo;Assessment of quantity and composition of illegaldumped municipal solid waste (MSW) in Delhi,&rdquo; Resour. Conserv.Recycl., vol. 141, pp. 54&ndash;60, Feb. 2019, doi:10.1016/j.resconrec.2018.10.012.</p>\r\n<p>[8] M. A. Hannan, M. Arebey, R. A. Begum, A. Mustafa, and H. Basri, &ldquo;Anautomated solid waste bin level detection system using Gabor waveletfilters and multilayer perception,&rdquo; Resour. Conserv. Recycl., vol. 72, pp.33&ndash;42, Mar. 2013, doi: 10.1016/j.resconrec.2012.12.002.</p>\r\n<p>[9] A. Malakahmad and N. D. Khalil, &ldquo;Solid waste collection system inIpoh city Solid Waste Collection System In Ipoh City:A Review,&rdquo; 2011Int. Conf. Business, Eng. Ind. Appl., no. March, pp. 174&ndash;179, 2016, doi:10.1109/ICBEIA.2011.5994236.</p>\r\n<p>[10] M. A. Hannan, M. Arebey, R. A. Begum, and H. Basri, &ldquo;RadioFrequency Identification ( RFID ) and communication technologies forsolid waste bin and truck monitoring system,&rdquo; Waste Manag., vol. 31,no. 12, pp. 2406&ndash;2413, 2011, doi: 10.1016/j.wasman.2011.07.022.</p>\r\n<p>[11] K. Kawai and T. Tasaki, &ldquo;Revisiting estimates of municipal solid wastegeneration per capita and their reliability,&rdquo; J. Mater. Cycles WasteManag., vol. 18, pp. 1&ndash;13, Jan. 2016, doi: 10.1007/s10163-015-0355-1.</p>\r\n<p>[12] M. Haraguchi, A. Siddiqi, and V. Narayanamurti, &ldquo;Stochastic costbenefit analysis of urban waste-to-energy systems,&rdquo; J. Clean. Prod., vol.224, pp. 751&ndash;765, Jul. 2019, doi: 10.1016/j.jclepro.2019.03.099.</p>\r\n<p>[13] K. L. P. Nguyen, Y. H. Chuang, H. W. Chen, and C. C. Chang, &ldquo;Impactsof socioeconomic changes on municipal solid waste characteristics inTaiwan,&rdquo; Resour. Conserv. Recycl., vol. 161, Oct. 2020, doi:10.1016/j.resconrec.2020.104931.</p>\r\n<p>[14] Z. Ceylan, S. Bulkan, and S. Elevli, &ldquo;Prediction of medical wastegeneration using SVR, GM (1,1) and ARIMA models: a case study formegacity Istanbul,&rdquo; J. Environ. Heal. Sci. Eng., vol. 18, no. 2, pp. 687&ndash;697, Dec. 2020, doi: 10.1007/s40201-020-00495-8.</p>\r\n<p>[15] M. Bagheri, R. Esfilar, M. S. Golchi, and C. A. Kennedy, &ldquo;Acomparative data mining approach for the prediction of energy recoverypotential from various municipal solid waste,&rdquo; Renew. Sustain. EnergyRev., vol. 116, Dec. 2019, doi: 10.1016/j.rser.2019.109423.</p>\r\n<p>[16] P. Nowakowski and T. PamuÃ…â€ša, &ldquo;Application of deep learning objectclassifier to improve e-waste collection planning,&rdquo; Waste Manag., vol.109, pp. 1&ndash;9, 2020, doi: 10.1016/j.wasman.2020.04.041.</p>\r\n<p>[17] M. W. Rahman, R. Islam, A. Hasan, N. I. Bithi, M. M. Hasan, and M.M. Rahman, &ldquo;Intelligent waste management system using deep learningwith IoT,&rdquo; J. King Saud Univ. - Comput. Inf. Sci., Sep. 2020, doi:10.1016/j.jksuci.2020.08.016.</p>\r\n<p>[18]Z. Ye, J. Yang, N. Zhong, X. Tu, J. Jia, and J. Wang, &ldquo;Tacklingenvironmental challenges in pollution controls using artificialintelligence: A review,&rdquo; Science of the Total Environment, vol. 699.Elsevier, Jan. 10, 2020, doi: 10.1016/j.scitotenv.2019.134279.</p>\r\n<p>[19] L. Chhay, M. A. H. Reyad, R. Suy, M. R. Islam, and M. M. Mian,&ldquo;Municipal solid waste generation in China: influencing factor analysisand multi-model forecasting,&rdquo; J. Mater. Cycles Waste Manag., vol. 20,no. 3, pp. 1761&ndash;1770, 2018, doi: 10.1007/s10163-018-0743-4.</p>\r\n<p>[20] M. Z. Joharestani, C. Cao, X. Ni, B. Bashir, and S. Talebiesfandarani,&ldquo;PM2.5 prediction based on random forest, XGBoost, and deep learningusing multisource remote sensing data,&rdquo; Atmosphere (Basel)., vol. 10,no. 7, p. 373, Jul. 2019, doi: 10.3390/atmos10070373.</p>\r\n<p>[21] W. Xia, Y. Jiang, X. Chen, and R. Zhao, &ldquo;Application of machinelearning algorithms in municipal solid waste management: A minireview,&rdquo; Waste Management and Research. SAGE PublicationsSageUK: London, England, pp. 1&ndash;16, Jul. 16, 2021, doi:10.1177/0734242X211033716.</p>\r\n<p>[22] G. L. Huang, J. He, Z. Xu, and G. Huang, &ldquo;A combination model basedon transfer learning for waste classification,&rdquo; Concurr. Comput. , vol.32, no. 19, pp. 1&ndash;12, 2020, doi: 10.1002/cpe.5751.</p>\r\n<p>[23] K. Ahmad, K. Khan, and A. Al-Fuqaha, &ldquo;Intelligent Fusion of DeepFeatures for Improved Waste Classification,&rdquo; IEEE Access, vol. 8, pp.96495&ndash;96504, 2020, doi: 10.1109/ACCESS.2020.2995681.</p>\r\n<p>[24] A. A. A. G. S. Altikat, &ldquo;Intelligent solid waste classification using deepconvolutional neural networks,&rdquo; Int. J. Environ. Sci. Technol., pp. 1&ndash;8,2021, doi: 10.1007/s13762-021-03179-4.</p>\r\n<p>[25] A. H. Vo, L. Hoang Son, M. T. Vo, and T. Le, &ldquo;A Novel Framework forTrash Classification Using Deep Transfer Learning,&rdquo; IEEE Access, vol.7, pp. 178631&ndash;178639, 2019, doi: 10.1109/ACCESS.2019.2959033.</p>\r\n<p>[26] M. Valente, H. Silva, J. M. L. P. Caldeira, V. N. G. J. Soares, and P. D.Gaspar, &ldquo;Detection of waste containers using computer vision,&rdquo; Appl.Syst. Innov., vol. 2, no. 1, pp. 1&ndash;13, 2019, doi: 10.3390/asi2010011.</p>\r\n<p>[27] O. Adedeji and Z. Wang, &ldquo;Intelligent waste classification system usingdeep learning convolutional neural network,&rdquo; Procedia Manuf., vol. 35,pp. 607&ndash;612, 2019, doi: 10.1016/j.promfg.2019.05.086.</p>\r\n<p>[28] M. ToÃ„Å¸a&ccedil;ar, B. Ergen, and Z. C&ouml;mert, &ldquo;Waste classification usingAutoEncoder network with integrated feature selection method inconvolutional neural network models,&rdquo; Meas. J. Int. Meas. Confed., vol.153, 2020, doi: 10.1016/j.measurement.2019.107459.</p>\r\n<p>[29] D. Ziouzios, D. Tsiktsiris, N. Baras, and M. Dasygenis, &ldquo;A DistributedArchitecture for Smart Recycling Using Machine Learning,&rdquo; Futur.Internet, vol. 12, no. 9, p. 141, 2020, doi: 10.3390/fi12090141.</p>\r\n<p>[30] Y. Chu, C. Huang, X. Xie, B. Tan, S. Kamal, and X. Xiong, &ldquo;Multilayerhyid deep-learning method for waste classification and recycling,&rdquo;Comput. Intell. Neurosci., vol. 2018, pp. 1&ndash;9, 2018, doi:10.1155/2018/5060857.</p>\r\n<p>[31] M. Cubillos, &ldquo;Multi-site household waste generation forecasting using adeep learning approach,&rdquo; Waste Manag., vol. 115, pp. 8&ndash;14, 2020, doi:10.1016/j.wasman.2020.06.046.</p>\r\n<p>[32] D. Niu, F. Wu, S. Dai, S. He, and B. Wu, &ldquo;Detection of long-term effectin forecasting municipal solid waste using a long short-term memoryneural network,&rdquo; J. Clean. Prod., vol. 290, pp. 1&ndash;8, 2021, doi:10.1016/j.jclepro.2020.125187.</p>\r\n<p>[33] A. Hussain et al., &ldquo;Waste Management and Prediction of Air PollutantsUsing IoT and Machine Learning Approach,&rdquo; Energies, vol. 13, no. 15,pp. 3930&ndash;3951, 2020.</p>\r\n<p>[34] F. Fasano, A. S. Addante, B. Valenzano, and G. Scannicchio, &ldquo;VariablesInfluencing per Capita Production , Separate Collection , and Costs ofMunicipal Solid Waste in the Apulia Region ( Italy ): An Experience ofDeep Learning,&rdquo; Int. J. Environ. Res. Public Health, vol. 18, no. 2, pp.752&ndash;774, 2021.</p>\r\n<p>[35] L. A. Akanbi, A. O. Oyedele, L. O. Oyedele, and R. O. Salami, &ldquo;Deeplearning model for Demolition Waste Prediction in a circular economy,&rdquo;J. Clean. Prod., vol. 274, no. 2020, 2020, doi:10.1016/j.jclepro.2020.122843.</p>\r\n<p>[36] Z. Kang, J. Yang, G. Li, and Z. Zhang, &ldquo;An Automatic GarbageClassification System Based on Deep Learning,&rdquo; IEEE Access, vol. 8,pp. 140019&ndash;140029, 2020, doi: 10.1109/ACCESS.2020.3010496.</p>\r\n<p>[37] M. Anjum and M. S. Umar, &ldquo;Garbage localization based on weakly supervised learning in Deep Convolutional Neural Network,&rdquo; in Proceedings - IEEE 2018 International Conference on Advances in Computing, Communication Control and Networking, ICACCCN 2018, Oct. 2018, pp. 1108&ndash;1113, doi: 10.1109/ICACCCN.2018.8748568.</p>\r\n<p>[38] R. N. Torres and P. Fraternali, &ldquo;Learning to identify illegal landfills through scene classification in aerial images,&rdquo; Remote Sens., vol. 13, no. 22, pp. 1&ndash;21, Nov. 2021, doi: 10.3390/rs13224520.</p>\r\n<p>[39] F. Zhang, C. Cao, C. Li, Y. Liu, and D. Huisingh, &ldquo;A systematic review of recent developments in disaster waste management,&rdquo; J. Clean. Prod., vol. 235, pp. 822&ndash;840, 2019, doi: 10.1016/j.jclepro.2019.06.229.</p>\r\n<p>[40] B. Kitchenham and S. Charters, &ldquo;Guidelines for performing systematic literature reviews in software engineering,&rdquo; in Technical report, Ver. 2.3 EBSE Technical Report. EBSE, 2007, p. 65.</p>\r\n<p>[41] M. Abdallah, M. Abu Talib, S. Feroz, Q. Nasir, H. Abdalla, and B. Mahfood, &ldquo;Artificial intelligence applications in solid waste management: A systematic research review,&rdquo; Waste Manag., vol. 109, pp. 231&ndash;246, 2020, doi: 10.1016/j.wasman.2020.04.057.</p>', 'Solid waste management; systematic literature review; deep learning; convolutional neural networks', '<p>[42] M. Staples and M. Niazi, &ldquo;Systematic review of organizational motivations for adopting CMM-based SPI,&rdquo; Inf. Softw. Technol., vol.50, no. 7&ndash;8, pp. 605&ndash;620, 2008.</p>\r\n<p>[43] W. Reim, V. Parida, and D. &Ouml;rtqvist, &ldquo;Product-Service Systems (PSS)business models and tactics - A systematic literature review,&rdquo; J. Clean.Prod., vol. 97, pp. 61&ndash;75, Jun. 2015, doi: 10.1016/j.jclepro.2014.07.003.</p>\r\n<p>[44] United Nations, Human Development Report 2020. 2020.</p>\r\n<p>[45] A. Annarelli, C. Battistella, and F. Nonino, &ldquo;Product service system: Aconceptual framework from a systematic review,&rdquo; Journal of CleanerProduction, vol. 139. Elsevier Ltd, pp. 1011&ndash;1032, Dec. 15, 2016, doi:10.1016/j.jclepro.2016.08.061.</p>\r\n<p>[46] T. J. Sheng et al., &ldquo;An Internet of Things Based Smart WasteManagement System Using LoRa and Tensorflow Deep LearningModel,&rdquo; IEEE Access, vol. 8, pp. 148793&ndash;148811, 2020, doi:10.1109/ACCESS.2020.3016255.</p>\r\n<p>[47] J. Bai, S. Lian, Z. Liu, K. Wang, and D. Liu, &ldquo;Deep learning based robotfor automatically picking up garbage on the grass,&rdquo; IEEE Trans.Consum. Electron., vol. 64, no. 3, pp. 382&ndash;389, 2019.</p>\r\n<p>[48] S. Jagtap, C. Bhatt, J. Thik, and S. Rahimifard, &ldquo;Monitoring potatowaste in food manufacturing using image processing and internet ofthings approach,&rdquo; Sustain., vol. 11, no. 11, pp. 1&ndash;12, 2019, doi:10.3390/su11113173.</p>\r\n<p>[49] W. L. Mao, W. C. Chen, C. T. Wang, and Y. H. Lin, &ldquo;Recycling wasteclassification using optimized convolutional neural network,&rdquo; Resour.Conserv. Recycl., vol. 164, no. August 2020, p. 105132, 2021, doi:10.1016/j.resconrec.2020.105132.</p>\r\n<p>[50] P. Ping, G. Xu, E. Kumala, and J. Gao, &ldquo;Smart Street Litter Detectionand Classification Based on Faster R-CNN and Edge Computing,&rdquo; Int. J.Softw. Eng. Knowl. Eng., vol. 30, no. 4, pp. 537&ndash;553, 2020, doi:10.1142/S0218194020400045.</p>\r\n<p>[51] P. Zhang, Q. Zhao, J. Gao, W. Li, and J. Lu, &ldquo;Urban Street CleanlinessAssessment Using Mobile Edge Computing and Deep Learning,&rdquo; IEEEAccess, vol. 7, pp. 63550&ndash;63563, 2019, doi: 10.1109/ACCESS.2019.2914270.</p>\r\n<p>[52] K. M. Bobulski J, &ldquo;Waste classification system using image processingand convolutional neural networks,&rdquo; Int. Work. Artif. Neural Networks,2019 Jun 12, Springer, Cham., pp. 350&ndash;361, 2019, [Online]. Available:http://dx.doi.org/10.1007/978-3-030-20518-8_30.</p>\r\n<p>[53] S. Kumar, D. Yadav, H. Gupta, O. P. Verma, I. A. Ansari, and C. W.Ahn, &ldquo;A novel yolov3 algorithm-based deep learning approach for wastesegregation: Towards smart waste management,&rdquo; Electron., vol. 10, no.1, pp. 1&ndash;20, 2021, doi: 10.3390/electronics10010014.</p>\r\n<p>[54] S. Liang and Y. Gu, &ldquo;A deep convolutional neural network tosimultaneously localize and recognize waste types in images,&rdquo; WasteManag., vol. 126, pp. 247&ndash;257, 2021, doi: 10.1016/j.wasman.2021.03.017.</p>\r\n<p>[55] D. O. Melinte, A. M. Travediu, and D. N. Dumitriu, &ldquo;Deepconvolutional neural networks object detector for real-time wasteidentification,&rdquo; Appl. Sci., vol. 10, no. 20, pp. 1&ndash;18, 2020, doi:10.3390/app10207301.</p>\r\n<p>[56] P. Davis, F. Aziz, M. T. Newaz, W. Sher, and L. Simon, &ldquo;The classification of construction waste material using a deep convolutional neural network,&rdquo; Autom. Constr., vol. 2021, 2021, doi: 10.1016/j.autcon.2020.103481.</p>\r\n<p>[57] H. Wang, Y. Li, L. M. Dang, J. Ko, D. Han, and H. Moon, &ldquo;Smartphone-based bulky waste classification using convolutional neural networks,&rdquo; Multimed. Tools Appl., vol. 79, no. 39&ndash;40, pp. 29411&ndash;29431, 2020, doi: 10.1007/s11042-020-09571-5.</p>\r\n<p>[58] O. I. Funch, R. Marhaug, S. Kohtala, and M. Steinert, &ldquo;Detecting glass and metal in consumer trash bags during waste collection using convolutional neural networks,&rdquo; Waste Manag., vol. 119, pp. 30&ndash;38, 2021, doi: 10.1016/j.wasman.2020.09.032.</p>\r\n<p>[59] M. H. Huynh, P. T. Pham-Hoai, A. K. Tran, and T. D. Nguyen, &ldquo;Automated Waste Sorting Using Convolutional Neural Network,&rdquo; Proc. - 2020 7th NAFOSTED Conf. Inf. Comput. Sci. NICS 2020, pp. 102&ndash; 107, 2020, doi: 10.1109/NICS51282.2020.9335897.</p>\r\n<p>[60] V. P. intha, R. Rekha, J. Nandhini, N. Sreekaarthick, and B. Ishwaryaa, &ldquo;Automatic Classi fi cation of Solid Waste Using Deep Learning,&rdquo; in Proceedings of International Conference on Artificial Intelligence, Smart Grid and Smart City Applications, 2019, pp. 881&ndash; 889, doi: 10.1007/978-3-030-24051-6_83.</p>\r\n<p>[61] H. Panwar et al., &ldquo;AquaVision: Automating the detection of waste in water bodies using deep transfer learning,&rdquo; Case Stud. Chem. Environ. Eng., vol. 2, Sep. 2020, doi: 10.1016/j.cscee.2020.100026.</p>\r\n<p>[62] W. Sterkens, D. Diaz-Romero, T. Goedem&eacute;, W. Dewulf, and J. R. Peeters, &ldquo;Detection and recognition of batteries on X-Ray images of waste electrical and electronic equipment using deep learning,&rdquo; Resour. Conserv. Recycl., vol. 168, May 2021, doi: 10.1016/j.resconrec.2020. 105246.</p>\r\n<p>[63] O. Youme, T. Bayet, J. M. Dembele, and C. Cambier, &ldquo;Deep Learning and Remote Sensing: Detection of Dumping Waste Using UAV,&rdquo; in Procedia Computer Science, Jan. 2021, vol. 185, pp. 361&ndash;369, doi: 10.1016/j.procs.2021.05.037.</p>\r\n<p>[64] J. Bobulski and M. Kubanek, &ldquo;Deep Learning for Plastic Waste Classification System,&rdquo; Appl. Comput. Intell. Soft Comput., vol. 2021, pp. 1&ndash;7, 2021, doi: 10.1155/2021/6626948.</p>\r\n<p>[65] C. Shi, C. Tan, T. Wang, and L. Wang, &ldquo;A waste classification method based on a multilayer hyid convolution neural network,&rdquo; Appl. Sci., vol. 11, no. 18, pp. 1&ndash;19, Sep. 2021, doi: 10.3390/app11188572.</p>\r\n<p>[66] C. Wang, J. Qin, C. Qu, X. Ran, C. Liu, and B. Chen, &ldquo;A smart municipal waste management system based on deep-learning and Internet of Things,&rdquo; Waste Manag., vol. 135, pp. 20&ndash;29, Nov. 2021, doi: 10.1016/j.wasman.2021.08.028.</p>\r\n<p>[67] B. M. Allan, D. G. Nimmo, D. Ierodiaconou, J. VanDerWal, L. P. Koh, and E. G. Ritchie, &ldquo;Futurecasting ecological research: the rise of technoecology,&rdquo; Ecosphere, vol. 9, no. 5, May 2018, doi: 10.1002/ecs2.2163.</p>\r\n<p>[68] J. J. Valletta, C. Torney, M. Kings, A. Thornton, and J. Madden, &ldquo;Applications of machine learning in animal behaviour studies,&rdquo; Animal Behaviour, vol. 124. Academic Press, pp. 203Ã¢â‚¬â€œ220, Feb. 01, 2017, doi: 10.1016/j.anbehav.2016.12.005.</p>\r\n<p>[69] I. Goodfellow, Y. Bengio, and A. Courville, Deep learning. 2016.</p>\r\n<p>[70] Y. Lecun, Y. Bengio, and G. Hinton, &ldquo;Deep learning,&rdquo; Nature, vol. 521, no. 7553, pp. 436&ndash;444, 2015, doi: 10.1038/nature14539.</p>\r\n<p>[71] A. Kumar, C. P. Gandhi, Y. Zhou, R. Kumar, and J. Xiang, &ldquo;Improved deep convolution neural network (CNN) for the identification of defects in the centrifugal pump using acoustic images,&rdquo; Appl. Acoust., vol. 167, p. 107399, Oct. 2020, doi: 10.1016/j.apacoust.2020.107399.</p>\r\n<p>[72] F. Seide, A. A.-P. of the 22nd A. SIGKDD, and U. 2016, &ldquo;CNTK: Microsoft&rsquo;s open-source deep-learning toolkit,&rdquo; in Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2016, pp. 2135&ndash;2135, [Online]. Available: <a href=\\\\\\\"https://dl.acm.org/doi/abs/10.1145/2939672.2945397.\\\\\\\">https://dl.acm.org/doi/abs/10.1145/2939672.2945397. </a></p>\r\n<p>[73] C. J. Abadi, Mart&iacute;n, Barham P, &ldquo;{TensorFlow} A system for large-scale machine learning,&rdquo; in 12th USENIX symposium on operating systems design and implementation (OSDI 16), 2016, pp. 265&ndash;283, [Online]. Available: https://www.usenix.org/conference/osdi16/technical-sessions/ presentation/abadi.</p>\r\n<p>[74] J. Nickolls and W. J. Dally, &ldquo;The GPU computing era,&rdquo; IEEE Micro, vol. 30, no. 2, pp. 56&ndash;69, 2010, doi: 10.1109/MM.2010.41.</p>\r\n<p>[75] S. Majchrowska et al., &ldquo;Deep learning-based waste detection in natural and urban environments,&rdquo; Waste Manag., vol. 138, pp. 274&ndash;284, Feb. 2022, doi: 10.1016/j.wasman.2021.12.001.</p>\r\n<p>[76] M. Abbasi and A. El Hanandeh, &ldquo;Forecasting municipal solid waste generation using artificial intelligence modelling approaches.,&rdquo; Waste Manag., vol. 56, pp. 13&ndash;22, 2016, doi: 10.1016/j.wasman.2016.05.018.</p>\r\n<p>[77] H. Niska and A. Serkkola, &ldquo;Data analytics approach to create waste generation profiles for waste management and collection,&rdquo; Waste Manag., vol. 77, pp. 477&ndash;485, Jul. 2018, doi: 10.1016/j.wasman.2018.04.033.</p>\r\n<p>[78] C. Birgen, E. Magnanelli, P. Carlsson, &Oslash;. Skreiberg, J. Mosby, and M. Becidan, &ldquo;Machine learning based modelling for lower heating value prediction of municipal solid waste,&rdquo; Fuel, vol. 283, Jan. 2021, doi: 10.1016/j.fuel.2020.118906.</p>\r\n<p>[79] B. Fallah, K. T. W. Ng, H. L. Vu, and F. Torabi, &ldquo;Application of a multi-stage neural network approach for time-series landfill gas modeling with missing data imputation,&rdquo; Waste Manag., vol. 116, pp. 66&ndash;78, Oct. 2020, doi: 10.1016/j.wasman.2020.07.034.</p>\r\n<p>[80] J. Soto-Paz et al., &ldquo;A New Approach for the Optimization of Biowaste Composting Using Artificial Neural Networks and Particle Swarm Optimization,&rdquo; Waste and Biomass Valorization, vol. 11, no. 8, pp. 3937&ndash;3951, Aug. 2020, doi: 10.1007/s12649-019-00716-8.</p>\r\n<p>[81] D. Wang and Y. Shang, &ldquo;A new active labeling method for deep learning,&rdquo; in Proceedings of the International Joint Conference on Neural Networks, Sep. 2014, pp. 112&ndash;119, doi: 10.1109/IJCNN.2014.6889457.</p>\r\n', '64dccb1a6d043.jpg');
INSERT INTO `project` (`id_project`, `title`, `team`, `abstract`, `background`, `methods`, `results`, `discussion`, `conclusions`, `references`, `keyword`, `references2`, `gambarName`) VALUES
(89, 'Impact of Modern Technology in Education', 'R. Raja*, P. C. Nagasubramani Department of Pedagogical Sciences, Tamilnadu Teachers Education University, Karapakkam, Chennai - 600 097, Tamil Nadu, India', 'Technology is a gift of God. After the gift of life it is perhaps the greatest of God\\\\\\\'s gifts. It is the mother of civilizations, of arts and of sciences. Technology has certainly changed the way we live. It has impacted different facets of life and redefined living. Undoubtedly, technology plays an important role in every sphere of life. Several manual tasks can be automated, thanks to technology. Also, many complex and critical processes can be carried out with ease and greater efficiency with the help of modern technology. Thanks to the application of technology, living has changed and it has changed for better. Technology has revolutionized the field of education. The importance of technology in schools cannot be ignored. In fact, with the onset of computers in education, it has become easier for teachers to impart knowledge and for students to acquire it. The use of technology has made the process of teaching and learning all the more enjoyable', 'The era of 21st century is often regarded as an era of technology. Technology, today, plays a very important role in our life. It is seen as a basis of growth of an economy. An economy which is poor in technology can never grow in today&rsquo;s scenario. This is because technology makes our work much easier and less time consuming. The impact of technology can be felt in every possible field one such field is Education.', '<p><strong>Modern technology in education</strong><br />According to the latest insights as to how exactly modern students of today prefer to use technology and how does their learning get an impact if they use technology, it was revealed that the use of modern equipment technology and tools, the learning and interactivity of students increases. They also find it much more interactive, as well as full of interesting areas, when aided by technology. The transfer of knowledge becomes very easy and convenient, as well as effective. What this means is, that our minds now tend to work faster when assisted with the use of modern technology, be it any part of life, here we talk about education. The reliance and dependence of such an innovation, that simply makes life an easy, smooth journey is completely unavoidable these days even in schools, universities and colleges. Students today can make use of technology in the following ways:<br /><em>Internet connection and round the clock connectivity</em><br />The internet has grown in importance by many folds, over the process of decade. Its importance in the education world can now never be undermined. Despite the chances of fraud and drawbacks, the use of the internet is like a blessing for students. Today, the internet is something that is present in almost everything we use. From television to gaming consoles, and our phones, the internet is literally everywhere. The use of the internet allows students to find amazing convenience, they can find various kinds of help, tutorials and other kinds of assisting material which could be used to academically improve and enhance their learning.<br /><em>Using projectors and visuals</em><br />Visual images always have a strong appeal compared to words. Using projectors and visuals to aid in learning is another form of great technological use. Top institutions around the world, now rely on the use of amazing PowerPoint presentations and projections in order to keep the learning interactive and interesting. Technological use such as projectors within the schools and colleges can take the interaction and interest levels right up and also improve motivation. Students like to see appealing visuals and something that entices them to think rather than just reading words. The learning part also becomes pretty efficient when it comes to technology.<br /><em>Digital footprint in the education sector</em><br />If we talk about digital and education, then the penetration of digital media within the education sector has now grown. This penetration has resulted in round the clock connectivity with students and different forums that are available for different kinds of assignments or help. As the power of digital increases, there are and there will be more applications that will assist students in development and learning.<br /><em>Online degrees with the use of technology</em><br />Online degrees now have become a very common phenomenon. People wish to take up online courses for theirlearning and certifications. Top institutions offer amazing online programs with the use of various applications and the internet. This is a concept that will continue to rise as it gets more support and awareness. The online degree scenario around the world is more famous among students who work and look for flexible studying programs.</p>\r\n<p><strong>Importance of technology in education</strong><br />The role of technology in the field of education is fourfold: it is included as a part of the curriculum, as an instructional delivery system, as a means of aiding instructions and also as a tool to enhance the entire learning process. Thanks to technology; education has gone from passive and reactive to interactive and aggressive.</p>\r\n<p>Education is essential in corporate and academic settings. In the former, education or training is used to help workers do things differently than they did before. In the latter; education is geared towards creating curiosity in the minds of students. In either case, the use of technology can help students understand and retain concepts better.</p>\r\n<p><strong>Factors affecting technology in education</strong><br />I. Jung talks about the enormous challenge teachers are facing in our society due to the rapid expansion of knowledge. The modern technologies are demanding that teachers learn how to use these technologies in their teaching. Hence these new technologies increase the teachers\\\\\\\' training needs. Gressard and Loyd (1985) asserted that teacher\\\\\\\'s attitudes toward computers are a key factor in the successful implementation of ICT in education. They pointed out that teachers do not always have positive attitudes towards computers and their poor attitudes may lead to a failure of the computer- based projects. Also the most commonly cited barriers are:</p>\r\n<ul>\r\n<li><p>lack of time;</p></li>\r\n<li><p>lack of access;</p></li>\r\n<li><p>lack of resources;</p></li>\r\n<li><p>lack of expertise and</p></li>\r\n<li><p>lack of support.</p></li>\r\n</ul>\r\n<p>Another barrier given by Butler and Sellbom (2002) and Chizmar &amp; Williams (2001) is reliability. Reliability included hardware failures, incompatible software between home and school, poor or slow internet connectivity and out of date software which are available mostly at school while the student</p>', '<strong>Impact of ICT on education</strong>\r\n<p>In educational context, ICT has the potential to increase access to education and improve its relevance and quality. Tinio (2002) asserted that ICT has a tremendous impact on education in terms of acquisition and absorption of knowledge to both teachers and students through the promotion of:</p>\r\n<ul>\r\n<li><p><em>Active learning</em>: </p> ICT tools help for the calculation and analysis of information obtained for examination and also students\\\\\\\' performance report are all being computerized and made easily available for inquiry. In contrast to memorization-based or rote learning, ICT promotes learner engagement as learners choose what to learn at their own pace and work on real life situations\\\\\\\' problems.&nbsp;</li>\r\n<li><p><em>Collaborative and Cooperative learning</em>: </p> ICT encourages interaction and cooperation among students, teachers regardless of distance which is between them. It also provides students the chance to work with people from different cultures and working together in groups, hence help students to enhance their communicative skills as well as their global awareness. Researchers have found that typically the use of ICT leads to more cooperation among learners within and beyond school and there exists a more interactive relationship between students and teachers (Gr&eacute;goire et al., 1996). \\\\\\\"Collaboration is a philosophy of interaction and personal lifestyle where individuals are responsible for their actions, including learning and respect the abilities and contributions of their peers.\\\\\\\" (Panitz, 1996).&nbsp;</li>\r\n<li><p><em>Creative Learning></em>: </p>ICT promotes the manipulation of existing information and to create one\\\\\\\'s own knowledge to produce a tangible product or a given instructional purpose.&nbsp;</li>\r\n<li><p><em>Integrative learning</em>:</p> ICT promotes an integrative approach to teaching and learning, by eliminating the synthetic separation between theory and practice unlike in the traditional classroom where emphasis encloses just a particular aspect.&nbsp;</li>\r\n<li><p><em>Evaluative learning</em>: </p> Use of ICT for learning is student-centered and provides useful feedback through various interactive features. ICT allow students to discover and learn through new ways of teaching and learning which are sustained by constructivist theories of learning rather than students do memorization and rote learning.</li>\r\n</ul>\r\n<p><strong><em>Positive Impact</em></strong></p>\r\n\r\n<p><em>Enhanced Teaching and Learning:</em></p>\r\n\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>Technological developments like digital cameras, projectors, mind training software, computers, Power point presentations, 3D visualization tools; all these have become great sources for teachers to help students grasp a concept easily.</li>\r\n<li>It has to be understood that visual explanation of concepts makes learning fun and enjoyable for students. They&rsquo;re able to participate more in the classroom and even teachers get a chance to make their classes more interactive and interesting.</li>\r\n</ul>\r\n<p><em>Globalization:</em></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>When school in different parts of the state, students can &ldquo;meet&rdquo; their counterparts through video conferencing without leaving the classroom.</li>\r\n<li>Some sites, such as www.glovico.com are used to help students learn foreign languages online by pairing a group of students with a teacher from another country</li>\r\n</ul>\r\n<p><em>No Geographical Limitations</em></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>With the introduction of online degree programs there is hardly any need of being present physically in the classroom. Even several foreign universities have started online degree courses that student can join.&nbsp;</li>\r\n<li>Distance learning and online education have become very important part of the education system now a day.</li>\r\n</ul>\r\n<p><strong><em>Negative Impact</em></strong></p>\r\n<p><em>Declining Writing Skills: </em></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>Due to the excessive usage of online chatting and shortcuts, the writing skills of today&rsquo;s young generation have declined quite tremendously.</li>\r\n<li>These days, children are relying more and more on digital communication that they have totally forgot about improving their writing skills.</li>\r\n<li>They don&rsquo;t know the spelling of different words, how to use grammar properly or how to do cursive writing.</li>\r\n</ul>\r\n<p><em>Increasing Incidents of Cheating: </em></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>Technological developments like graphical calculators, high tech watches, mini cameras and similar equipment have become great sources to cheat in exams.</li>\r\n<li>It is easier for students to write formulas and notes on graphing calculators, with least chances of being caught.</li>\r\n<li>They don&rsquo;t know the spelling of different words, how to use grammar properly or how to do cursive writing.</li>\r\n</ul>\r\n<p><em>Lack of Focus:</em></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>&nbsp;SMS or text messaging has become a favorite pastime of many students. Students are seen playing with their cell phone, iPhones day and night or driving and very often even between lectures.</li>\r\n<li>Being ever-connected to the online world has resulted in lack of focus and concentration in academics and to some extent, even in sports and extracurricular activities.</li>\r\n</ul>', '<p><strong>Advantages</strong></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>It makes students more excited to learn.</li>\r\n<li>Help students with busy schedules, freedom to work at home on their own time.</li>\r\n<li>Train students to learn new technology skills they can use later in the work place.</li>\r\n<li>Decrease paper and photocopying costs, promoting concept of &ldquo;green revolution&rdquo;.</li>\r\n</ul>\r\n<p><br /><strong>Disadvantages</strong></p>\r\n<ul style=\\\\\\\"list-style-type: square;\\\\\\\">\r\n<li>Many experts and experienced people say that, due to such technology in education, students imagination is affected, their thinking ability is reduced.</li>\r\n<li>Sometime it&rsquo;s also time-consuming from teacher&rsquo;s point of view.</li>\r\n<li>It is costly to install such technology.</li>\r\n<li>There can be health issues too when used over limit</li>\r\n<li>Some students can&rsquo;t afford modern computer technologies.</li>\r\n</ul>', '<p>Technology has a positive impact on education and at the same time may also pose negative effects. Teachers and students should take advantage of this in the good light and eliminate the drawbacks which are pulling back many of students as well as schools from achieving excellence. It is thus time for every country to introduce a more technologically equipped education sector in the future.</p>', '<ol>\r\n<li>Beringer, V. (2009, October 20) For kids, pen&rsquo;s mightier than keyboard. futurity.org. Retrieved February 25th 2013 from <a href=\\\\\\\"http://www.futurity.org/society-culture/forkids-pens-mightier-than\\\\\\\">http://www.futurity.org/society-culture/forkids-pens-mightier-than </a>keyboard/#more-4909.</li>\r\n<li>Bounds, G. ( 2010, October 5) How handwriting trains the brain &ndash; forming letters is key to learning, memory, idea. wsj.com. Retrieved February 25th 2013 from <a href=\\\\\\\"http://online.wsj.com/article/SB1000142405274870463\\\\\\\">http://online.wsj.com/article/SB1000142405274870463</a> 1504575531932754922518.html</li>\r\n<li>Bransford, J., Brown, A., &amp; Cocking, R. (2000). How people learn: Brain, mind, experience, and school. Washington, DC: National Academic Press.</li>\r\n<li>Brill, J. M., &amp; Galloway, C. (2007). Perils and promises: University instructors&rsquo; integration of technology in classroom-based practices. British Journal of Educational Technology. 38(1), 95-105. Leising, J. (2013 January 30) The new script for teaching handwriting is no script at all. wsj.com Retrieved February 25th 2013 from <a href=\\\\\\\"http://online.wsj.com/article/SB1000142412788732364\\\\\\\">http://online.wsj.com/article/SB1000142412788732364</a> 4904578272151551627948.html?KEYWORDS=handwriting</li>\r\n<li>Roschelle, J., Pea, R., Hoadley, C., Gordin, D., &amp; Means, B. (2000). Future of children, 10(2), 76-101. Shah (2011, July 16) Why does writing make us smart ? huffingpost.com. Retrieved February 25th 2013 from <a href=\\\\\\\"http://www.huffingtonpost.com/2011/07/16/whydoes-writing-make-us\\\\\\\">http://www.huffingtonpost.com/2011/07/16/whydoes-writing-make-us</a> _n_900638.html</li>\r\n<li>Wenglinski, H. (1998). Does it compute? The relationship between educational technology and student achievement in mathematics. Princeton, NJ: ETS.</li>\r\n</ol>', ' Education, modern technology, teaching', '', '64dcd3eb26cc2.jpg');
INSERT INTO `project` (`id_project`, `title`, `team`, `abstract`, `background`, `methods`, `results`, `discussion`, `conclusions`, `references`, `keyword`, `references2`, `gambarName`) VALUES
(90, 'Survey of Machine Learning Algorithms for Disease Diagnostic', 'Meherwar Fatima, Maruf Pasha <br> Institute of CS & IT, The Women University Multan, Multan, Pakistan <br> Department of Information Technology, Bahauddin Zakariya University, Multan, Pakistan', 'In medical imaging, Computer Aided Diagnosis (CAD) is a rapidly growing\r\ndynamic area of research. In recent years, significant attempts are made for\r\nthe enhancement of computer aided diagnosis applications because errors in\r\nmedical diagnostic systems can result in seriously misleading medical treatments. Machine learning is important in Computer Aided Diagnosis. After using an easy equation, objects such as organs may not be indicated accurately.\r\nSo, pattern recognition fundamentally involves learning from examples. In the\r\nfield of bio-medical, pattern recognition and machine learning promise the\r\nimproved accuracy of perception and diagnosis of disease. They also promote\r\nthe objectivity of decision-making process. For the analysis of high-dimensional\r\nand multimodal bio-medical data, machine learning offers a worthy approach\r\nfor making classy and automatic algorithms. This survey paper provides the\r\ncomparative analysis of different machine learning algorithms for diagnosis of\r\ndifferent diseases such as heart disease, diabetes disease, liver disease, dengue\r\ndisease and hepatitis disease. It brings attention towards the suite of machine\r\nlearning algorithms and tools that are used for the analysis of diseases and decision-making process accordingly.', 'Artificial Intelligence can enable the computer to think. Computer is made much\r\nmore intelligent by AI. Machine learning is the subfield of AI study. Various researchers think that without learning, intelligence cannot be developed. There\r\nare many types of Machine Learning Techniques that are shown in Figure 1. Supervised, Unsupervised, Semi Supervised, Reinforcement, Evolutionary Learning and Deep Learning are the types of machine learning techniques. These techniques are used to classify the data set.\r\n1) Supervised learning: Offered a training set of examples with suitable targets\r\nand on the basis of this training set, algorithms respond correctly to all feasible\r\ninputs. Learning from exemplars is another name of Supervised Learning. Classification and regression are the types of Supervised Learning.\r\nClassification: It gives the prediction of Yes or No, for example, â€œIs this tumor\r\ncancerous?â€, â€œDoes this cookie meet our quality standards?â€\r\nRegression: It gives the answer of â€œHow muchâ€ and â€œHow manyâ€.\r\n2) Unsupervised learning: Correct responses or targets are not provided. Unsupervised learning technique tries to find out the similarities between the input\r\ndata and based on these similarities, un-supervised learning technique classify\r\nthe data. This is also known as density estimation. Unsupervised learning contains clustering [1].\r\nClustering: it makes clusters on the basis of similarity.\r\n3) Semi supervised learning: Semi supervised learning technique is a class of\r\nsupervised learning techniques. This learning also used unlabeled data for training purpose (generally a minimum amount of labeled-data with a huge amount\r\nof unlabeled-data). Semi-supervised learning lies between unsupervised-learning\r\n(unlabeled-data) and supervised learning (labeled-data).\r\n4) Reinforcement learning: This learning is encouraged by behaviorist psychology. Algorithm is informed when the answer is wrong, but does not inform\r\nthat how to correct it. It has to explore and test various possibilities until it finds\r\nthe right answer. It is also known as learning with a critic. It does not recommend improvements. Reinforcement learning is different from supervised learning g in the sense that accurate input and output sets are not offered, nor suboptimal actions clearly prÃ©cised. Moreover, it focuses on on-line performance.\r\n5) Evolutionary Learning: This biological evolution learning can be considered as a learning process: biological organisms are adapted to make progress\r\nin their survival rates and chance of having off springs. By using the idea of fitness, to check how accurate the solution is, we can use this model in a computer\r\n[1].\r\n6) Deep learning: This branch of machine learning is based on set of algorithms. In data, these learning algorithms model high-level abstraction. It uses\r\ndeep graph with various processing layer, made up of many linear and nonlinear\r\ntransformation.\r\nPattern recognition process and data classification are valuable for a long\r\ntime. Humans have very strong skill for sensing the environment. They take\r\naction against what they perceive from environment [2]. Big data turns into\r\nChunks due to multidisciplinary combined effort of machine learning, databases\r\nand statistics. Today, in medical sciences disease diagnostic test is a serious task.\r\nIt is very important to understand the exact diagnosis of patients by clinical examination and assessment. For effective diagnosis and cost effective management, decision support systems that are based upon computer may play a vital\r\nrole. Health care field generates big data about clinical assessment, report regarding patient, cure, follow-ups, medication etc. It is complex to arrange in a\r\nsuitable way. Quality of the data organization has been affected due to inappropriate management of the data. Enhancement in the amount of data needs some\r\nproper means to extract and process data effectively and efficiently [3]. One of\r\nthe many machine-learning applications is employed to build such classifier that\r\ncan divide the data on the basis of their attributes. Data set is divided into two or\r\nmore than two classes. Such classifiers are used for medical data analysis and\r\ndisease detection.\r\nInitially, algorithms of ML were designed and employed to observe medical\r\ndata sets. Today, for efficient analysis of data, ML recommended various tools.\r\nEspecially in the last few years, digital revolution has offered comparatively lowcost and obtainable means for collection and storage of data. Machines for data\r\ncollection and examination are placed in new and modern hospitals to make them\r\ncapable for collection and sharing data in big information systems. Technologies\r\nof ML are very effective for the analysis of medical data and great work is done\r\nregarding diagnostic problems. Correct diagnostic data are presented as a medical record or reports in modern hospitals or their particular data section. To run\r\nan algorithm, correct diagnostic patient record is entered in a computer as an\r\ninput. Results can be automatically obtained from the previous solved cases. Physicians take assistance from this derived classifier while diagnosing novel patient\r\nat high speed and enhanced accuracy. These classifiers can be used to train nonspecialists or students to diagnose the problem [4].\r\nIn past, ML has offered self-driving cars, speech detection, efficient web search,\r\nand improved perception of the human generation. Today machine learning is present everywhere so that without knowing it, one can possibly use it many\r\ntimes a day. A lot of researchers consider it as the excellent way in moving towards human level. The machine learning techniques discovers electronic health\r\nrecord that generally contains high dimensional patterns and multiple data sets.\r\nPattern recognition is the theme of MLT that offers support to predict and make\r\ndecisions for diagnosis and to plan treatment. Machine learning algorithms are\r\ncapable to manage huge number of data, to combine data from dissimilar resources, and to integrate the background information in the study [3].\r\n', '2. Diagnosis of Diseases by Using Different Machine\r\nLearning Algorithms\r\nMany researchers have worked on different machine learning algorithms for\r\ndisease diagnosis. Researchers have been accepted that machine-learning algorithms work well in diagnosis of different diseases. Figurative approach of diseases diagnosed by Machine Learning Techniques is shown in Figure 2. In this\r\nsurvey paper diseases diagnosed by MLT are heart, diabetes, liver, dengue and\r\nhepatitis.\r\n2.1. Heart Disease\r\nOtoom et al. [5] presented a system for the purpose of analysis and monitoring.\r\nCoronary artery disease is detected and monitored by this proposed system.\r\nCleveland heart data set is taken from UCI. This data set consists of 303 cases\r\nand 76 attributes/features. 13 features are used out of 76 features. Two tests with\r\nthree algorithms Bayes Net, Support vector machine, and Functional Trees FT\r\nare performed for detection purpose. WEKA tool is used for detection. After experimenting Holdout test, 88.3% accuracy is attained by using SVM technique.\r\nIn Cross Validation test, Both SVM and Bayes net provide the accuracy of 83.8%.\r\n81.5% accuracy is attained after using FT. 7 best features are picked up by using\r\nBest First selection algorithm. For validation Cross Validation test are used. By\r\napplying the test on 7 best selected features, Bayes Net attained 84.5% of correctness, SVM provides 85.1% accuracy and FT classify 84.5% correctly.\r\nVembandasamy et al. [6] performed a work, to diagnose heart disease by using\r\nNaive Bayes algorithm. Bayes theorem is used in Naive Bayes. Therefore, Naive\r\nBayes have powerful independence assumption. The employed data-set are obtained from one of the leading diabetic research institute in Chennai. Data set\r\nconsists of 500 patients. Weka is used as a tool and executes classification by using 70% of Percentage Split. Naive Bayes offers 86.419% of accuracy.\r\nUse of data mining approaches has been suggested by Chaurasia and Pal [7]\r\nfor heart disease detection. WEKA data mining tool is used that contains a set of\r\nmachine learning algorithms for mining purpose. Naive Bayes, J48 and bagging\r\nare used for this perspective. UCI machine learning laboratory provide heart\r\ndisease data set that consists of 76 attributes. Only 11 attributes are employed for\r\nprediction. Naive bayes provides 82.31% accuracy. J48 gives 84.35% of correctness. 85.03% of accuracy is achieved by Bagging. Bagging offers better classification rate on this data set.\r\nParthiban and Srivatsa [8] put their effort for diagnosis of heart disease in diabetic patients by using the methods of machine learning. Algorithms of Naive\r\nBayes and SVM are applied by using WEKA. Data set of 500 patients is used that\r\nare collected from Research Institute of Chennai. Patients that have the disease\r\nare 142 and disease is missing in 358 patients. By using Naive Bayes Algorithm\r\n74% of accuracy is obtained. SVM provide the highest accuracy of 94.60.\r\nTan et al. [9] proposed hybrid technique in which two machine-learning algorithms named Genetic Algorithm (G.A) and Support Vector Machine (SVM) are\r\njoined effectively by using wrapper approach. LIBSVM and WEKA data mining\r\ntool are used in this analysis. Five data sets (Iris, Diabetes disease, disease of breast\r\nCancer, Heart and Hepatitis disease) are picked up from UC Irvine machine\r\nlearning repository for this experiment. After applying GA and SVM hybrid approach, 84.07% accuracy is attained for heart disease. For data set of diabetes\r\n78.26% accuracy is achieved. Accuracy for Breast cancer is 76.20%. Correctness\r\nof 86.12% is resulting for hepatitis disease. Graphical representation of Accuracy\r\naccording to time for detection of heart disease is shown in Figure 3.\r\nAnalysis:\r\nIn existing literature, SVM offers highest accuracy of 94.60% in 2012 as in Table 1. In many application areas, SVM shows good performance result. Attribute\r\nor features used by Parthiban and Srivatsa in 2012 are correctly responded by\r\nSVM. In 2015, Otoom et al. used SVM variant called SMO. It also uses FS technique to find best features. SVM responds to these features and offers the accuracy of 85.1% but it is comparatively low as in 2012. Training and testing set of\r\nboth data sets are different, as well as, data types are different. Advantages and Disadvantages of SVM:\r\nAdvantages: Construct correct classifiers and fewer over fitting, robust to\r\nnoise.\r\nDisadvantages: It is a binary classifier. For the classification of multi-class, it\r\ncan use pair wise classification. Its Computational cost is high, so it runs slow\r\n[10].\r\n2.2. Diabetes Disease\r\nIyer et al. [11] has performed a work to predict diabetes disease by using decision tree and Naive Bayes. Diseases occur when production of insulin is insufficient or there is improper use of insulin. Data set used in this work is Pima Indian diabetes data set. Various tests were performed using WEKA data mining\r\ntool. In this data-set percentage split (70:30) predict better than cross validation.\r\nJ48 shows 74.8698% and 76.9565% accuracy by using Cross Validation and Percentage Split Respectively. Naive Bayes presents 79.5652% correctness by using\r\nPS. Algorithms shows highest accuracy by utilizing percentage split test. \r\nMeta learning algorithms for diabetes disease diagnosis has been discussed by\r\nSen and Dash [12]. The employed data set is Pima Indians diabetes that is received from UCI Machine Learning laboratory. WEKA is used for analysis. CART,\r\nAdaboost, Logiboost and grading learning algorithms are used to predict that\r\npatient has diabetes or not. Experimental results are compared on the behalf of\r\ncorrect or incorrect classification. CART offers 78.646% accuracy. The Adaboost\r\nobtains 77.864% exactness. Logiboost offers the correctness of 77.479%. Grading\r\nhas correct classification rate of 66.406%. CART offers highest accuracy of 78.646%\r\nand misclassification Rate of 21.354%, which is smaller as compared to other\r\ntechniques.\r\nAn experimental work to predict diabetes disease is done by the Kumari and\r\nChitra [13]. Machine learning technique that is used by the scientist in this experiment is SVM. RBF kernel is used in SVM for the purpose of classification.\r\nPima Indian diabetes data set is provided by machine learning laboratory at\r\nUniversity of California, Irvine. MATLAB 2010a are used to conduct experiment.\r\nSVM offers 78% accuracy.\r\nSarwar and Sharma [14] have suggested the work on Naive Bayes to predict\r\ndiabetes Type-2. Diabetes disease has 3 types. First type is Type-1 diabetes, Type-2\r\ndiabetes is the second type and third type is gestational diabetes. Type-2 diabetes\r\ncomes from the growth of Insulin resistance. Data set consists of 415 cases and\r\nfor purpose of variety; data are gathered from dissimilar sectors of society in India. MATLAB with SQL server is used for development of model. 95% correct\r\nprediction is achieved by Naive Bayes.\r\nEphzibah [15] has constructed a model for diabetes diagnosis. Proposed model joins the GA and fuzzy logic. It is used for the selection of best subset of features and also for the enhancement of classification accuracy. For experiment,\r\ndataset is picked up from UCI Machine learning laboratory that has 8 attributes\r\nand 769 cases. MATLAB is used for implementation. By using genetic algorithm\r\nonly three best features/attributes are selected. These three attributes are used by\r\nfuzzy logic classifier and provide 87% accuracy. Around 50% cost is less than the\r\noriginal cost. Table 2 provides the Comprehensive view of Machine learning Techniques for diabetes disease diagnosis.\r\nAnalysis:\r\nNaive Bayes based system is helpful for diagnosis of Diabetes disease. Naive\r\nBayes offers highest accuracy of 95% in 2012. The results show that this system\r\ncan do good prediction with minimum error and also this technique is important to diagnose diabetes disease. But in 2015, accuracy offered by Naive Bayes is\r\nlow. It presents 79.5652% or 79.57% accuracy. This proposed model for detection of Diabetes disease would require more training data for creation and testing. Figure 4 shows the Accuracy graph of Algorithms for the diagnosis of Diabetes disease according to time.\r\nAdvantages and Disadvantages of Naive Bayes:\r\nAdvantages: It enhances the classification performance by eliminating the unrelated features. Its performance is good. It takes less computational time.\r\nDisadvantages: This algorithm needs large amount of data to attain good outcomes. It is lazy as they store entire the training examples [16].', '2.3. Liver Disease\r\nVijayarani and Dhayanand [17] predict the liver disease by using Support vector\r\nmachine and Naive bayes Classification algorithms. ILPD data set is obtained\r\nfrom UCI. Data set comprises of 560 instances and 10 attributes. Comparison is\r\nmade on the basis of accuracy and time execution. Naive bayes shows 61.28%\r\ncorrectness in 1670.00 ms. 79.66% accuracy is attained in 3210.00 ms by SVM.\r\nFor implementation, MATLAB is used. SVM shows highest accuracy as compared to the Naive bayes for liver disease prediction. In terms of time execution,\r\nNaives bayes takes less time as compared to the SVM.\r\nA study on intelligent techniques to classify the liver patients is performed by\r\nthe Gulia et al. [18]. Used data set is picked up from UCI. WEKA data mining\r\ntool and five intelligent techniques J48, MLP, Random Forest, SVM and Bayesian Network classifiers are used in this experiment. In first step, all algorithms\r\nare applied on the original data set and get the percentage of correctness. In second step, feature selection method is applied on whole data-set to get the significant subset of liver patients and all these algorithms are used to test the subset of whole data-set. In third step they take comparison of outcomes before and\r\nafter feature selection. After FS, algorithms provide highest accuracy as J48 presents\r\n70.669% accuracy, 70.8405% exactness is achieved by the MLP algorithm, SVM\r\nprovides 71.3551% accuracy, 71.8696% accuracy is offered by Random forest and\r\nBayes Net shows 69.1252% accuracy.\r\nRajeswari and Reena [19] used the data mining algorithms of Naive Bayes, K\r\nstar and FT tree to analyze the liver disease. Data set is taken from UCI that\r\ncomprises of 345 instances and 7 attributes. 10 cross validation test are applied\r\nby using WEKA tool. Naive Bayes provide 96.52% Correctness in 0 sec. 97.10%\r\naccuracy is achieved by using FT tree in 0.2 sec. K star algorithm classify the instances about 83.47% accurately in 0 sec. On the basis of outcomes, highest classification accuracy is offered by FT tree on liver disease dataset as compared to\r\nother data mining algorithms. Table 3 presents the comprehensive view of algorithms for the detection of liver disease.\r\nAnalysis:\r\nTo diagnose liver disease, FT Tree Algorithm provides the highest result as\r\ncompare to the other algorithms. When FT tree algorithm is applied on the dataset\r\nof liver disease, time taken for result or building the model is fast as compared to\r\nother algorithms. According to its attribute, it shows the improved performance.\r\nThis algorithm fully classified the attributes and offers 97.10% correctness. From\r\nthe results, this Algorithm plays an important role in determining enhanced classification accuracy of data set. Accuracy graph of algorithms are shown in Figure 5.\r\nAdvantages and Disadvantages of FT:\r\nAdvantage: Easy to interpret and understand; Fast prediction.\r\nDisadvantage: Calculations are complex mainly if values are uncertain or if\r\nseveral outcomes are linked.\r\n2.4. Dengue Disease\r\nTarmizi et al. [20] performed a work for Malaysia Dengue Outbreak Detection by using the Models of Data Mining. Dengue is becoming a severe contagious\r\ndisease. It creates trouble in those countries where weather is humid for example\r\nThailand, Indonesia and Malaysia. Decision Tree (DT), Artificial Neural Network (ANN), and Rough Set Theory (RS) are the classification algorithms that\r\nare used in this study to predict dengue disease. Data set are taken from Public\r\nHealth Department of Selangor State. WEKA data mining tool with two tests (10\r\nCross-fold Validation and Percentage split) is used. By using 10-Cross fold validation DT offers 99.95% accuracy, ANN presents 99.98% of Correctness and RS\r\nshows 100% accuracy. After using PS, Both Decision tree and Artificial Neural\r\nNetwork gives 99.92% of correctness. RS achieves 99.72% accuracy.\r\nFathima and Manimeglai [21] performed a work to predict Arbovirus-Dengue\r\ndisease. Data mining algorithm that are used by these researchers are Support\r\nVector Machine. Data set for analysis is obtained from King Institute of Preventive Medicine and surveys of many hospitals and laboratories of Chennai and\r\nTirunelveli from India. It contains 29 attributes and 5000 samples. Data is examined by R project version 2.12.2. Accuracy that is achieved by SVM is 0.9042.\r\nIbrahim et al. [22] suggested a system in which Artificial neural network is\r\nused for forecasting the defervescence day of fever in patients of dengue disease.\r\nOnly clinical signs and symptoms are used by the proposed system for detection.\r\nThe data are gathered from 252 hospitalized patients, in which 4 patients are\r\nhaving DF (Dengue fever) and 248 patients are having DHF (dengue hemorrhagic fever). MATLABâ€™s neural network toolbox is used. Algorithm of Multilayer\r\nfeed-forward neural network (MFNN) is used in this experiment. Day of defervescence of fever is accurately predicted by MFNN in DF and DHF with 90%\r\ncorrectness.\r\nFigure 6 shows the accuracy graph of all algorithms for the diagnosis of Dengue disease.\r\nAnalysis:\r\nDifferent Machine learning techniques are used to diagnose dengue disease.\r\nDengue disease is one of the serious contagious diseases. As in Table 4, for detection of dengue disease, RS theory shows the highest result as compared to the other algorithms. In 2005 and 2012, researchers used different algorithms but\r\ndid not attain highest result and improvements. In 2013, accuracy is improved\r\nby using RS. It is capable to manage uncertainty, noise and missing data. For the\r\npurpose of classification, Developed RS classifier is based on the Rough set theory.\r\nSelection of attribute empowers the classifier to surpass the other models. RS is a\r\npromising rule based method that offers meaningful information. RS is also best\r\nfrom neural network in term of time. NN takes much time to build model. DT is\r\ncomplex as well as costly algorithm. RS does not need any initial and additional\r\ninformation about data but Decision tree needs information.\r\nAdvantages and Disadvantages of RS:\r\nAdvantages: It is very easy to understand and provides direct understanding\r\nof attained result. It evaluates data significance. It is appropriate for both qualitative and quantitative data. It discovers the hidden patterns. It also finds minimal set of data. It can find relationship that cannot be identified by statistical methods.\r\nDisadvantages: It has not so many limitations still it is not widely used.\r\n2.5. Hepatitis Disease\r\nBa-Alwi and Hintaya [23] suggested a comparative analysis. Data mining algorithms that are used for hepatitis disease diagnosis are Naive Bayes, Naive Bayes updatable, FT Tree, K Star, J48, LMT, and NN. Hepatitis disease data set was\r\ntaken from UCI Machine Learning repository. Classification results are measured in terms of accuracy and time. Comparative Analysis is taken by using\r\nneural connections and WEKA: data mining tool. Results that are taken by using\r\nneural connection are low than the algorithms used in WEKA. In this Analysis\r\nof Hepatitis disease diagnosis, second technique that is used is rough set theory,\r\nby using WEKA. Performance of Rough set procedure is better than NN specially\r\nin case of medical data analysis. Naive Bayes gives the accuracy of 96.52% in 0\r\nsec. 84% Accuracy is attained by the Naive Bayes Updateable algorithm in 0 sec.\r\nIn 0.2 sec FT Tree presents the accuracy of 87.10%. K star offers 83.47% Correctness. Time taken for K star algorithm is 0 sec. Correctness of 83% is achieved\r\nby J48 and time that J48 takes to classify is 0.03 sec. LMT provides 83.6% accuracy 0.6 sec. Neural network shows 70.41% of correctness. Naive Bayes is best\r\nclassification algorithm used in the rough set technique. It offers high accuracy\r\nin minimum time.\r\nKarlik [24] shows a comparative analysis of Naive Bayes and back propagation\r\nclassifiers to diagnose hepatitis disease. Key advantage of using these classifiers is\r\nthat they require small amount of data for categorization. Types of hepatitis are\r\nâ€œA, B, C, D and Eâ€. These are generated by different viruses of hepatitis. Rapid\r\nMiner open source software is used in this analysis. Hepatitis data set is taken\r\nfrom UCI. Data set include 20 features and 155 instances. 15 attributes are used\r\nin this experiment. Naive Bayes classifier gives 97% accuracy. Three-layered feedforward NN are used and trained with Back propagation algorithm 155 instances\r\nare used for training. Correctness of 98% is attained.\r\nSathyadevi [25] employed C4.5, ID3 and CART algorithms for diagnosing the\r\ndisease of hepatitis. This study uses the UCI hepatitis patient data set. WEKA,\r\ntool is used in this analysis. CART has offered great performance handling of\r\nmissing values. So, CART algorithm shows a highest classification accuracy of\r\n83.2%. ID3 Algorithm offers 64.8% of accuracy. 71.4% is attained by C4.5 algorithm. Binary decision tree (DT) that is generated by CART algorithm has only\r\ntwo or no child. DT that is formed by the C4.5 and ID3 can have two or more\r\nchildren. CART algorithm performs well in terms of Accuracy and time complexity.\r\nAnalysis:\r\nMany algorithms have been used for diagnosis of different diseases. Table 5\r\ngives the comprehensive view. For the detection of Hepatitis disease, Feed forward neural network with back propagation shows highest accuracy of 98%. Because in this model, three layered feed forward neural network is trained with\r\nerror back propagation algorithm. Back propagation training with the rule of delta\r\nlearning is an iterative gradient algorithm planned to lessen the RMSE â€œroot mean\r\nsquare errorâ€ between the real output of a multilayered feed-forward neural networks and a desired output. Every layer is connected to preceding layer and having\r\nno other connection. Second best result is offered by Naive Bayes. But in terms\r\nof time to build model, Naive Bayes runs fast as compare to neural network. Figurative approach for the detection of hepatitis is shown in Figure 7.\r\nAdvantages and Disadvantages of NN:\r\nAdvantages: Adaptive Learning, Self-Organization, Real Time Operation Fault\r\nTolerance via Redundant Information Coding.\r\nDisadvantages: Less over fitting needs great computational effort. Sample Size\r\nmust be large. Itâ€™s time consuming. Engineering Judgment does not develop the\r\nrelations between input and output variables so that the model behaves like a\r\nblack box [26].', '3. Discussions and Analysis of Machine Learning Techniques\r\nFor diagnosis of Heart, Diabetes, Liver, Dengue and Hepatitis diseases, several\r\nmachine-learning algorithms perform very well. From existing literature, it is\r\nobserved that Naive Bayes Algorithm and SVM are widely used algorithms for detection of diseases. Both algorithms offer the better accuracy as compare to\r\nother algorithms. Artificial Neural network is also very useful for prediction. It\r\nalso shows the maximum output but it takes more time as compared to other\r\nalgorithms. Trees algorithm are also used but they did not attain wide acceptance due to its complexity. They also shows enhanced accuracy when it responded correctly to the attributes of data set. RS theory is not widely used but it\r\npresents maximum output.', 'Statistical models for estimation that are not capable to produce good performance results have flooded the assessment area. Statistical models are unsuccessful to hold categorical data, deal with missing values and large data points.\r\nAll these reasons arise the importance of MLT. ML plays a vital role in many applications, e.g. image detection, data mining, natural language processing, and\r\ndisease diagnostics. In all these domains, ML offers possible solutions. This paper provides the survey of different machine learning techniques for diagnosis of\r\ndifferent diseases such as heart disease, diabetes disease, liver disease, dengue and\r\nhepatitis disease. Many algorithms have shown good results because they identify the attribute accurately. From previous study, it is observed that for the detection of heart disease, SVM provides improved accuracy of 94.60%. Diabetes disease is accurately diagnosed by Naive Bayes. It offers the highest classification\r\naccuracy of 95%. FT provides 97.10% of correctness for the liver disease diagnosis. For dengue disease detection, 100% accuracy is achieved by RS theory. The\r\nfeed forward neural network correctly classifies hepatitis disease as it provides\r\n98% accuracy. Survey highlights the advantages and disadvantages of these algorithms. Improvement graphs of machine learning algorithms for prediction of\r\ndiseases are presented in detail. From analysis, it can be clearly observed that these\r\nalgorithms provide enhanced accuracy on different diseases. This survey paper\r\nalso provides a suite of tools that are developed in community of AI. These tools\r\nare very useful for the analysis of such problems and also provide opportunity\r\nfor the improved decision making process.', '[1] Marshland, S. (2009) Machine Learning an Algorithmic Perspective. CRC Press,\r\nNew Zealand, 6-7.\r\n[2] Sharma, P. and Kaur, M. (2013) Classification in Pattern Recognition: A Review.\r\nInternational Journal of Advanced Research in Computer Science and Software Engineering, 3, 298.\r\n[3] Rambhajani, M., Deepanker, W. and Pathak, N. (2015) A Survey on Implementation of Machine Learning Techniques for Dermatology Diseases Classification. International Journal of Advances in Engineering & Technology, 8, 194-195.\r\n[4] Kononenko, I. (2001) Machine Learning for Medical Diagnosis: History, State of the\r\nArt and Perspective. Journal of Artificial Intelligence in Medicine, 1, 89-109.\r\n[5] Otoom, A.F., Abdallah, E.E., Kilani, Y., Kefaye, A. and Ashour, M. (2015) Effective\r\nDiagnosis and Monitoring of Heart Disease. International Journal of Software Engineering and Its Applications. 9, 143-156.\r\n[6] Vembandasamy, K., Sasipriya, R. and Deepa, E. (2015) Heart Diseases Detection\r\nUsing Naive Bayes Algorithm. IJISET-International Journal of Innovative Science,\r\nEngineering & Technology, 2, 441-444.\r\n[7] Chaurasia, V. and Pal, S. (2013) Data Mining Approach to Detect Heart Disease.\r\nInternational Journal of Advanced Computer Science and Information Technology\r\n(IJACSIT), 2, 56-66.\r\n[8] Parthiban, G. and Srivatsa, S.K. (2012) Applying Machine Learning Methods in Diagnosing Heart Disease for Diabetic Patients. International Journal of Applied Information Systems (IJAIS), 3, 25-30.\r\n[9] Tan, K.C., Teoh, E.J., Yu, Q. and Goh, K.C. (2009) A Hybrid Evolutionary Algorithm for Attribute Selection in Data Mining. Journal of Expert System with Applications, 36, 8616-8630. https://doi.org/10.1016/j.eswa.2008.10.013\r\n[10] Karamizadeh, S., Abdullah, S.M., Halimi, M., Shayan, J. and Rajabi, M.J. (2014)\r\nAdvantage and Drawback of Support Vector Machine Functionality. 2014 IEEE International Conference on Computer, Communication and Control Technology\r\n(I4CT), Langkawi, 2-4 September 2014, 64-65.\r\nhttps://doi.org/10.1109/i4ct.2014.6914146\r\n[11] Iyer, A., Jeyalatha, S. and Sumbaly, R. (2015) Diagnosis of Diabetes Using Classification Mining Techniques. International Journal of Data Mining & Knowledge Management Process (IJDKP), 5, 1-14. https://doi.org/10.5121/ijdkp.2015.5101\r\n[12] Sen, S.K. and Dash, S. (2014) Application of Meta Learning Algorithms for the Prediction of Diabetes Disease. International Journal of Advance Research in Computer Science and Management Studies, 2, 396-401.\r\n[13] Kumari, V.A. and Chitra, R. (2013) Classification of Diabetes Disease Using Support Vector Machine. International Journal of Engineering Research and Applications (IJERA), 3, 1797-1801.', 'Machine Learning, Artificial Intelligence, Machine Learning Techniques', '[14] Sarwar, A. and Sharma, V. (2012) Intelligent NaÃ¯ve Bayes Approach to Diagnose\r\nDiabetes Type-2. Special Issue of International Journal of Computer Applications\r\n(0975-8887) on Issues and Challenges in Networking, Intelligence and Computing\r\nTechnologies-ICNICT 2012, 3, 14-16.\r\n[15] Ephzibah, E.P. (2011) Cost Effective Approach on Feature Selection using Genetic\r\nAlgorithms and Fuzzy Logic for Diabetes Diagnosis. International Journal on Soft\r\nComputing (IJSC), 2, 1-10. https://doi.org/10.5121/ijsc.2011.2101\r\n[16] Archana, S. and DR Elangovan, K. (2014) Survey of Classification Techniques in\r\nData Mining. International Journal of Computer Science and Mobile Applications,\r\n2, 65-71\r\n[17] Vijayarani, S. and Dhayanand, S. (2015) Liver Disease Prediction using SVM and\r\nNaÃ¯ve Bayes Algorithms. International Journal of Science, Engineering and Technology Research (IJSETR), 4, 816-820.\r\n[18] Gulia, A., Vohra, R. and Rani, P. (2014) Liver Patient Classification Using Intelligent Techniques. (IJCSIT) International Journal of Computer Science and Information Technologies, 5, 5110-5115.\r\n[19] Rajeswari, P. and Reena,G.S. (2010) Analysis of Liver Disorder Using Data Mining\r\nAlgorithm. Global Journal of Computer Science and Technology, 10, 48-52.\r\n[20] Tarmizi, N.D.A., Jamaluddin, F., Abu Bakar, A., Othman, Z.A., Zainudin, S. and\r\nHamdan, A.R. (2013) Malaysia Dengue Outbreak Detection Using Data Mining Models. Journal of Next Generation Information Technology (JNIT), 4, 96-107.\r\n[21] Fathima, A.S. and Manimeglai, D. (2012) Predictive Analysis for the ArbovirusDengue using SVM Classification. International Journal of Engineering and Technology, 2, 521-527.\r\n[22] Ibrahim, F., Taib, M.N., Abas, W.A.B.W., Guan, C.C. and Sulaiman, S. (2005) A\r\nNovel Dengue Fever (DF) and Dengue Haemorrhagic Fever (DHF) Analysis Using\r\nArtificial Neural Network (ANN). Computer Methods and Programs in Biomedicine, 79, 273-281. https://doi.org/10.1016/j.cmpb.2005.04.002\r\n[23] Ba-Alwi, F.M. and Hintaya, H.M. (2013) Comparative Study for Analysis the Prognostic in Hepatitis Data: Data Mining Approach. International Journal of Scientific\r\n& Engineering Research, 4, 680-685.\r\n[24] Karlik, B. (2011) Hepatitis Disease Diagnosis Using Back Propagation and the Naive\r\nBayes Classifiers. Journal of Science and Technology, 1, 49-62.\r\n[25] Sathyadevi, G. (2011) Application of CART Algorithm in Hepatitis Disease Diagnosis. IEEE International Conference on Recent Trends in Information Technology\r\n(ICRTIT), MIT, Anna University, Chennai, 3-5 June 2011, 1283-1287.\r\n[26] Singh, Y., Bhatia, P.K., and Sangwan, O. (2007) A Review of Studies on Machine\r\nLearning Techniques. International Journal of Computer Science and Security, 1,\r\n70-84', '64dcf70965007.jpg');
INSERT INTO `project` (`id_project`, `title`, `team`, `abstract`, `background`, `methods`, `results`, `discussion`, `conclusions`, `references`, `keyword`, `references2`, `gambarName`) VALUES
(99, 'Computer Science: The Third Pillar of Medical Education ', 'Frank Lau , Lindsay Katona , Joseph M. Rosen , Charles Everett Koop <br> Department of Surgery, Brigham & WomenÃ¢â‚¬â„¢s Hospital, Boston, USA <br> Thayer School of Engineering, Dartmouth College, Hanover, USA <br> Department of Surgery, Dartmouth-Hitchcock Medical Center, Lebanon, USA <br> Geisel School of Medicine, Dartmouth College, Hanover, USA', 'In 2001, the Institute of Medicine (IOM) and the National Academy of Sciences (NAS) attributed substantial problems in the quality of American medicine to four domains: growing complexity of science\r\nand technology; the increase in chronic conditions; a poorly organized delivery system; and constraints on\r\nexploiting the revolution in information technology (IT). Although all of these domains have been improved by IT systems within the last decade, the U.S. health care systems has been slow to adopt these\r\ndevelopments. We propose one way to combat such quality problems by incorporating a medicine-specific computer science (CS) curriculum as the third of Abraham FlexnerÃ¢â‚¬â„¢s pillars of medical education.', 'Meanwhile the requirements of medical education\r\nhave enormously increased. The fundamental sciences\r\nupon which medicine depends have been greatly extendedÃ¢â‚¬Â¦ The education of the medical practitioner\r\nunder these changed conditions makes entirely different demands in respect to both preliminary and\r\nprofessional training. ', 'FlexnerÃ¢â‚¬â„¢s first pillar of medical education was clinical experience. His report catalyzed rapid, systemic change, allowing\r\nexperimental science to become the second pillar. The subsequent fusion of research and teachingÃ¢â‚¬â€the academic medical\r\nschoolÃ¢â‚¬â€remains intact today.\r\nToday, medicine is slow to incorporate two forces that have\r\naltered nearly every aspect of our lives: computer science (CS)\r\nand information technologies (IT). The result is an inability to\r\nproperly address many of the mounting challenges and expectations of modern medicine. For example, electronic medical\r\nrecords (EMRs) are the modern standard, but Jha and colleagues (2011) found only 15% of hospitals used them as of\r\n2010.\r\nMany factors contribute to these delays. But fundamentally,\r\nvery few physicians have formal CS training. We are therefore\r\nhamstrung in implementing IT solutions. We are unqualified to\r\nparticipate in designing and developing transformative applications. We are poorly equipped to apply the intellectual rigor of\r\nCS in research and clinical problem solving.\r\nTo overcome this problem, one solution is to incorporate a\r\nformal, medicine-specific CS curriculum as the third pillar of\r\nmedical education.\r\nOn the surface, our proposal may seem heavy-handed. After\r\nall, an entire industry of IT professionals exists. And, the act of\r\nprogramming might seem unrelated to patient care. But CS and\r\nmedicine revolve around the same core processes: the gathering,\r\nstorage, and interpretation of data. Moreover, clinical and research data are increasingly digitized. By giving physicians the\r\nintellectual tools to deeply shape and understand healthcare IT,\r\nmedicine-specific CS education will be a boon to our profession. A parallel shift has started in journalism, with Columbia\r\nUniversity announcing a dual-degree program in journalism\r\nand computer science (2010).\r\nHistory makes a powerful case for incorporating CS into\r\nmedical education. Four paradigms have governed the progress\r\nof science (Bell, Hey, & Szalay, 2009). The first paradigm of\r\nempirical science relied on observations and empirical data.\r\nNext, we developed the second paradigm of theoretical science\r\n(e.g. NewtonÃ¢â‚¬â„¢s laws). FlexnerÃ¢â‚¬â„¢s report led American medical\r\neducation to adopt these two paradigms, ultimately yielding our\r\npresent-day models of physiology and disease.\r\nWith the advent of computing, the third paradigm of simulation (e.g. weather modeling) became possible. Today, in response to the data explosion of the past decade, a fourth paradigm of technologies for data-intensive science is rapidly\r\nemerging. These two paradigms fulfill clear needs within medicine. For example, physiology simulations offer the promise of\r\nintervention or drug testing without costly, time-intensive, and\r\npotentially dangerous clinical trials (Eddy & Schlessinger, 2003).\r\nSimilarly, the mountains of digitized, clinical data coming out\r\nof patient care settings make fourth paradigm tools a necessity.\r\nBy building the third pillar of medical education around these\r\nthird and fourth paradigms of science, we will generate benefits\r\nin the key realms of Patient Care, Education, Service, Research,\r\nand Finance. ', '<strong>Patient Care Benefits</strong>\r\nA CS-proficient physician workforce would drive the adoption of healthcare IT. Patient care would directly benefit. In\r\n2001Ã¢â‚¬â„¢s Ã¢â‚¬Å“Crossing the Quality Chasm: A New Health System for\r\nthe 21st Century,Ã¢â‚¬Â the Institute of Medicine (IOM) and the\r\nNational Academy of Sciences (NAS) found Ã¢â‚¬Å“abundant evidence\r\nthat serious and extensive quality problems exist throughout American medicine resulting in harm to many Americans.Ã¢â‚¬Â\r\nThis report highlighted 4 contributory domains: Ã¢â‚¬Å“growing complexity of science and technology, the increase in chronic conditions, a poorly organized delivery system, and constraints on\r\nexploiting the revolution in information technology.Ã¢â‚¬Â\r\nAll of these domains have been improved by information\r\ntechnology (IT) systems (Dexter, Perkins, Maharry, Jones, &\r\nMcDonald, 2004; Kucher et al., 2005; Litzelman, Dittus, Miller,\r\n& Tierney, 1993). These systems have been available for years.\r\nExamples include EMRs, computerized order entry systems,\r\nand electronic prescription systems. But adoption remains slow.\r\nBarriers to adoption include initial cost, physician time requirements, difficulties with technology, and inadequate support (Miller & Sim, 2004; Pizzi, Suh, Barone, & Nash, 2005).\r\nTellingly, several of these barriers stem from a lack of CS/IT\r\nliteracy. Physicians well-versed in computers would require\r\nless training, experience less initial difficulty, and would require less IT support.\r\nEleven years have passed since the IOM/NASÃ¢â‚¬â„¢s report without significant progress in applying IT to improve patient care.\r\nThe federal government is preparing to force the implementation of basic healthcare IT systems. Rather than be pushed\r\nalong, we should lead these efforts.\r\n<strong>Educational Benefits</strong>\r\nAs a pillar of medical education, CS benefits medical students and physicians in two discrete domains: critical thinking\r\nand lifelong learning. The optimal time for this training is during the preclinical years of medical school. This way ensures\r\nthat the CS courses are relevant to physician careers. This\r\nwould also set the stage for applying CS to lifelong learning, a\r\ncrucial task for physicians.\r\nWith regards to critical thinking, the learning process behind\r\nprogramming is uniquely well-suited to medicine: good programming has many parallels to good surgery. For example,\r\nprograms must be carefully designed in advance. Contingencies\r\nmust be planned for, vulnerabilities identified, and checks implemented. When things go wrong and the program needs debugging, the programmer must proceed step-wise through the\r\nprogram, considering all possible conflicts, until the problem is\r\nidentified. Good surgeons use similar processes to plan, execute,\r\nand problem-solve their surgeries. Unlike surgery, in CS these\r\nprocesses are easily reproducible and do not require a patient.\r\nIn this sense, CS offers the opportunity to sharpen critical\r\nthinking at an accelerated rate and in a safe setting.\r\nBy learning how to program, medical students will enhance\r\ntheir lifelong learning because they can develop applications\r\nspecifically for physician learning needs. This should be part of\r\ntheir CS training. For example, a medical student could write an\r\napplication to summarize key findings from the 80,000 clinical\r\ntrials that are conducted annually (ACRO, 2010). Such a program would yield lifelong returns by keeping our knowledge\r\nbase updated.\r\nAlternatively, a student could create a program to address the\r\nproblem of knowledge attrition. We know that physicians forget a tremendous amount of knowledge, even when that\r\nknowledge is clinically relevant. For example, Ali and colleagues (1996) found in a study involving practicing trauma\r\nphysicians that, 6 months after successfully completing an Advanced Trauma Life Support course, 50% failed a repeat test. A\r\nknowledge management program could track our rate of knowledge attrition and prompt us to review critical material before\r\nwe forget it.\r\nMedical students could drive the development of digital\r\nsimulators. In the past 7 years, non-medical simulation has\r\nadvanced tremendously. Powerful graphics cards allow for\r\nhighly realistic situational gaming and mobile gaming is everywhere. Despite these gains, digital simulation plays a small\r\nrole in medical education.\r\nWe propose that medical schools develop simulator platforms specifically for medical education. These platforms should\r\nfocus on effective learning (Issenberg, McGaghie, Petrusa, Lee\r\nGordon, & Scalese, 2005). They should allow clinical scenarios\r\nto be presented with high-fidelity. Students should be required\r\nto program their own simulations using these platforms.\r\nAnalogous to tradition of student presentations, the authoring of\r\nsimulations will help students delve into clinical entities. However, these simulations could be shared with other students,\r\nyielding a comprehensive educational library.\r\n<strong>Service Benefits</strong>\r\nService, or the contract between the patient and the physician,\r\nis the very heart of medicine. But a service gap now exists\r\n(Grumbach, 1999; Moore & Showstack, 2003). IT solutions\r\nhave been shown to improve this gap, but most physicians remain reluctant to implement them. Because computing proficiency correlates positively with healthcare IT adoption, CStrained physicians are better able to close the service gap\r\n(Kaushal, Bates, & Jenter, 2009).\r\nFor example, the American Medical Association published\r\nguidelines for clinical emails in 2001. As of 2006, Brooks and\r\nMenachemi found only 16.6% of Florida physicians used email\r\nto communicate with their patients. Security and legal concerns\r\nare oft-cited barriers to the adoption of email communications.\r\nSecurity concerns are no greater than those faced by the banking industry, which has safely launched online and mobile\r\nbanking platforms. Similarly, no lawsuits have ever been\r\nbrought for medical advice given via email.\r\nNewer technologies such as text messaging have been shown\r\nto improve patient compliance in the management of type 1\r\ndiabetes and liver transplants (Franklin, Waller, Pagliari, &\r\nGreene, 2006; Miloh et al., 2009). Videoconferencing and telemedicine also promise to restore the doctor-patient relationship\r\nwhile lowering overall costs. But until physicians attain a high\r\nlevel of comfort with information technologies, we expect a\r\nsignificant lag in using these tools to renew the patient-doctor\r\nrelationship. ', '<strong>Research & Innovation Benefits</strong>\r\nA CS-proficient physician workforce will reap benefits in\r\nresearch and innovation. The recent explosion of data from\r\nevery sector of medicine is currently an untapped gold mine. As\r\nclinical records become digitized, this volume of data will only\r\ngrow. From bioinformatics to clinical research, physicians who\r\npossess the intellectual framework for manipulating and understanding this data will generate novel insights. For example,\r\nwhen routine text-mining methods were applied to published\r\nabstracts, three novel rheumatoid arthritis risk loci were identified (Raychaudhuri et al., 2009).\r\nPhysicians who understand CS will drive healthcare IT innovation. For example, we currently lack national standards for\r\nEMR interoperability. Physicians should lead the development\r\nof these standards, but we cannot do so without CS fluency.\r\nMedical students should drive the development of learning\r\nplatforms. Motivated and trained physicians will finally push\r\nmedicine into the third and fourth paradigms of computer science, perhaps perfecting applications like the Archimedes model,\r\na full-scale simulation model of human physiology, diseases,\r\nbehaviors, interventions, and healthcare systems (Eddy & Schlessinger, 2003).\r\n<strong>Finance Benefits</strong>\r\nIn 2009, healthcare spending comprised 17.3% of the gross\r\ndomestic product (Truffer et al., 2010). This is projected to\r\ngrow to one third of national income by mid-century (Hagist &\r\nKotlikoff, 2006). A cornerstone of current governmental efforts\r\nto combat the rising cost is EMRs. Girosi (2005) projects $80\r\nbillion per year of cost savings if effective EMRs are implemented nationally. Given the current shortage of specialists\r\ncapable of supporting healthcare IT, the best strategy for driving this implementation is to broadly increase the number of\r\nCS-proficient physicians.\r\nThis physician workforce would also allow for the implementation of additional, technologically sophisticated healthcare IT solutions. Examples include Cybercare, a proposed\r\ndistributed network-based healthcare system that shifts the\r\nfocus back to preventive care (Koop et al., 2008). Other technologies such as telemedicine, remote monitoring, and robotics\r\nfor telesurgery/telemedicine can increase patient healthfulness,\r\naccess to care, and systemic efficiency. ', '<strong>Building the Third Pillar</strong>\r\nIntegrating CS into the medical school curriculum is a massive undertaking. But it is no larger than the integration of experimental science that took place a century ago and the benefits make it equally worthwhile. The proper development of this\r\ncurriculum should be undertaken by a national committee. Each\r\nmedical school should be evaluated to identify what is working,\r\nand more importantly, what is missing. Schools that do not\r\nuphold minimum standards need to implement a plan for getting up to speed. We believe medical students should, at a\r\nminimum, learn one scripting language, develop one databasedriven application, and create an extension for another program.\r\nTo maximize the medical relevance, this training must take\r\nplace in medical school.\r\nThe proposed process would capitalize on two theories of\r\neducation, namely social learning theory and constructivism.\r\nSocial learning theory would be most valuable during the studentsÃ¢â‚¬â„¢ introduction to a scripting language. Instructors, perhaps\r\nin a virtual form, could model programming techniques while\r\ndemonstrating their applications to medicine (Ormrod, 1999).\r\nIn accordance with constructivism, the students will build confidence through mastery of a scripting language. When challenged to develop a database-driven application, they would\r\ncement their role as active participants at the intersection of CS\r\nand medicine. By creating an extension for another program,\r\nthey would be responsible for refining their skills in a way that\r\nthey deem relevant. This merger of theories would ideally be\r\naccomplished within learning and digital simulation platforms\r\n(Sharma, Xiem Hsieh, Hsieh, & Yoo, 2008). Considering the\r\npotential to blend learning theories with emerging technology,\r\nthe construction of this third pillar of medicine presents a worthy yet manageable endeavor. ', 'ACRO (2010). The CRO market. http://www.acrohealth.org/61\r\nAli, J., Cohen R., Adam, R., Gana, T. J., Pierre, I., Ali, E., Bedaysie, H.\r\net al. (1996). Attrition of cognitive and trauma management skills\r\nafter the Advanced Trauma Life Support (ATLS) course. Journal of\r\nTrauma and Acute Care Surgery,40, 860-866.\r\ndoi:10.1097/00005373-199606000-00002\r\nAmerican Medical Association (2001). Guidelines for physician-patient\r\nelectronic communications.\r\nhttp://www.ama-assn.org/ama/pub/about-ama/our-people/member-gr\r\noups-sections/young-physicians-section/advocacy-resources/guidelin\r\nes-physician-patient-electronic-communications.shtml\r\nCommittee on Quality of Health Care in America (2001). Crossing the\r\nquality chasm: A new health system for the 21st century. Washington,\r\nDC: National Academies Press.\r\nBell, G., Hey, T., & Szalay, A. (2009). Computer science. Beyond the\r\ndata deluge. Science, 323, 1297-1298. doi:10.1126/science.1170411\r\nBrooks, R. G., & Menachemi, N. (2006). PhysiciansÃ¢â‚¬â„¢ use of email with\r\npatients: Factors influencing electronic communication and adherence to best practices. Journal of Medical Internet Research, 8, e2.\r\ndoi:10.2196/jmir.8.1.e2\r\nColumbia University (2010). Columbia University announces new dualdegree MasterÃ¢â‚¬â„¢s program in journalism and computer science.\r\nhttp://news.columbia.edu/oncampus/1980.\r\nDexter, P. R., Perkins, S. M., Maharry, K. S., Jones, K., & McDonald,\r\nC. J. (2004). Inpatient computer-based standing orders vs physician\r\nreminders to increase influenza and pneumococcal vaccination rates:\r\nA randomized trial. Journal of the American Medical Association, 292,\r\n2366-2371. doi:10.1001/jama.292.19.2366\r\nEddy, D. M., & Schlessinger, L. (2003). Validation of the Archimedes\r\ndiabetes model. Diabetes Care, 26, 3102-3110.\r\ndoi:10.2337/diacare.26.11.3102\r\nFlexner, A. (1910). Medical education in the United States and Canada.\r\nBoston, MA: The Merrymount Press.\r\nFranklin, V. L., Waller, A., Pagliari, C., & Greene, S. A. (2006). A randomized controlled trial of Sweet Talk, a text-messaging system to\r\nsupport young people with diabetes. Diabetic Medicine, 23, 1332-1338.\r\ndoi:10.1111/j.1464-5491.2006.01989.x\r\nGirosi, F. (2005). Extrapolating evidence of health information technology savings and costs. Santa Monica, CA: RAND Corporation.\r\nGrumbach, K. (1999). Primary care in the United StatesÃ¢â‚¬â€The best of\r\ntimes, the worst of times. New England Journal of Medicine, 341,\r\n2008-2010. doi:10.1056/NEJM199912233412611\r\nHagist, C., & Kotlikoff, L. J. (2006). Health care spending: What the\r\nfuture will look like. Dallas, TX: National Center for Policy Analysis,\r\nBoston University, National Bureau of Economic Research.\r\nIssenberg, S. B., McGaghie, W. C., Petrusa, E. R., Lee, G. D., &\r\nScalese, R. J. (2005). Features and uses of high-fidelity medical\r\nsimulations that lead to effective learning: A BEME systematic review.\r\nMedical Teacher, 27, 10-28. doi:10.1080/01421590500046924\r\nJha, A. K., Burke, M. F., DesRoches, C. M., Joshi, M. S., Kralovec, P.\r\nD., Campbell, E. G., & Buntin, M. B. (2011). Progress toward meaningful use: HospitalsÃ¢â‚¬â„¢ adoption of electronic health records. American Journal of Managing Care, 17, 117-124.\r\nKaushal, R., Bates, D. W., Jenter, C. A., Mills, S. A., Volk, L. A., Burdick, E. et al. (2009). Imminent adopters of electronic health records\r\nin ambulatory care. Informatics in Primary Care, 17, 7-15.\r\nKoop, C. E., Mosher, R., Kun, L., Geiling, J., Grigg, E., Long, S. et al.\r\n(2008). Future delivery of health care: Cybercare. IEEE Engineering\r\nin Medicine and Biology Magazine, 27, 29-38.\r\ndoi:10.1109/MEMB.2008.929888\r\nKucher, N., Koo, S., Quiroz, R., Cooper, J. M., Paterno, M. D., Soukonnikov, B., & Goldhaber, S. Z. (2005). Electronic alerts to prevent\r\nvenous thromboembolism among hospitalized patients. New England\r\nJournal of Medicine, 352, 969-977. doi:10.1056/NEJMoa041533\r\nLitzelman, D. K., Dittus, R. S., Miller, M. E., & Tierney, W. M. (1993).\r\nRequiring physicians to respond to computerized reminders improves their compliance with preventive care protocols. Journal of General\r\nInternal Medicine, 8, 311-317. doi:10.1007/BF02600144', 'Information Technology; Computer Science; Medical Education', 'Miller, R. H., & Sim, I. (2004). PhysiciansÃ¢â‚¬â„¢ use of electronic medical\r\nrecords: Barriers and solutions. Health Affairs (Millwood), 23, 116-\r\n126. doi:10.1377/hlthaff.23.2.116\r\nMiloh, T., Annunziato, R., Arnon, R., Warshaw, J., Parkar, S., Suchy, F.\r\net al. (2009). Improved adherence and outcomes for pediatric liver\r\ntransplant recipients by using text messaging. Pediatrics, 124, e844-\r\ne850. doi:10.1542/peds.2009-0415\r\nMoore, G., & Showstack, J. (2003). Primary care medicine in crisis:\r\nToward reconstruction and renewal. Annals of Internal Medicine, 138,\r\n244-247.\r\nOrmrod, J. E. (1999). Human learning (3rd ed.). Upper Saddle River,\r\nNJ: Merrill Prentice Hall.\r\nPizzi, L. T., Suh, D., Barone, J., & Nash, D. B. (2005). Factors related\r\nto physiciansÃ¢â‚¬â„¢ adoption of electronic prescribing: Results from a national survey. American Journal of Medical Quality, 20, 22-32.\r\ndoi:10.1177/1062860604273775\r\nRaychaudhuri, S., Thomson, B. P., Remmers, E. F., Eyre, S., Hinks, A.,\r\nGuiducci, C. et al. (2009). Genetic variants at CD28, PRDM1 and\r\nCD2/CD58 are associated with rheumatoid arthritis risk. Nature Genetics, 41, 1313-1318. doi:10.1038/ng.479\r\nSharma, P., Xie, Y., Hseih, P., Hseih, W., & Yoo, S. (2008). Student\r\nlearning outcomes in technology-enhanced constructivist learning\r\nenvironments: What does research show? In M. Orey, V. J. McClendon,\r\n& R. M. Branch (Eds.), Educational media and technology yearbook\r\n2008 (pp. 77-90). Westwood, CT: Greenwood Publishing Group, Inc.\r\nTruffer, C. J., Keehan, S., Smith, S., Cylus, J., Sisko, A., Poisal, J. A. et\r\nal. (2010). Health spending projections through 2019: The recessionÃ¢â‚¬â„¢s\r\nimpact continues. Health Affairs (Millwood), 29, 522-529.\r\ndoi:10.1377/hlthaff.2009.1074', '64dd0d9eb41c2.jpg');
INSERT INTO `project` (`id_project`, `title`, `team`, `abstract`, `background`, `methods`, `results`, `discussion`, `conclusions`, `references`, `keyword`, `references2`, `gambarName`) VALUES
(100, 'Cogniton-based Enlightenment of Creative Thinking: Examplars in Computer Science', 'Zhi-Quan Cheng, Shiyao Jin <br>School of Computer, National University of Defense Technology, Hunan Province, China', ' It is reputed that â€œGenius is 1% inspiration and 99% perspirationâ€, but it can also be noted that\r\nâ€œsometimes, 1% inspiration is more important than 99% perspiration.â€ As this 1% is so important, can it\r\nbe understood, and even learned? If so, how can cognition be used to enlighten a scientist\\\'s inspiration\r\n(creative thinking)? Both questions are considered on the basis of cognitive theory in the paper. We illustrate our ideas with examples from computer science.', 'â€œGenius is one percent inspiration and ninety-nine percent\r\nperspiration, but sometimes, one-percent inspiration is more\r\nimportant than ninety-nine percent perspirationâ€ is a quote\r\nusually attributed to Edison, when discussing his remarkable\r\nachievements. Generally, the later part of this saying is neglected when quoted, as the goal is to encourage hard work,\r\nrather than to point out the key role of distinguished scientists,\r\nlike Edison, as a creative elite.\r\nScientific research, searching for new knowledge, appeals\r\nespecially to individual creative people. Edward De Bono (De\r\nBono, 2008), the father of creative thinking, suggested that\r\ncreativeness is a particular way of thinking, and postulated that\r\nthere are some basic principles and mental techniques that are\r\ncommonly used while being creative. 150 years ago, Claude\r\nBernard, the great French physiologist said (Bernard, 1865):\r\nâ€œThe genius of inventiveness maybe diminished or even smothered by a poor method, while a good method may increase\r\nand develop itâ€¦ In biological science, the role of method is\r\neven more importantâ€¦â€. These statements argue that the\r\none-percent perspiration can be understood, and even learnt, in\r\nsome way.\r\nIn our paper, using cognitive theory (BermÃºdez, 2010), we\r\nexplore how to understand creativity, and enlighten researchers\r\nin creative thinking (Sternberg, 2006). Our arguments are\r\nmainly addressed by using advances in computer science as\r\nexemplars, particularly in the areas of computer graphics and\r\nsimulation. We explore creative habits of mind, and try to catch\r\nthe insights how to generally improve one\\\'s creative thinking\r\nabilities, and how to apply them to new situations. Our work is\r\ncarrying out at the difficult state of traditional methods pausing\r\nfor about a decade (Mumford, 2003), and try to deal with it\r\nwith new progress of computer science.', '<strong>Cognition and Creative Thinking for Scientists</strong>\r\nDe Bono (De Bono, 2008) stated: â€œCreative thinking is not a\r\ntalent, it is a skill that can be learnt. It empowers people, adding\r\nstrength to their natural abilities, which improves teamwork,\r\nproductivity and where appropriate, profitsâ€. For a senior scientist, mental processes are the essence and the engine of creative\r\nendeavor. When a mind containing a wealth of information\r\ncontemplates a problem, relevant information readily comes to\r\ninto focus during thinking. A critical issue in problem solving is\r\ndeciding whether the available information is sufficient or not.\r\nSince the information available in the mind must be recognized,\r\nwe address the relationship between cognition and creative\r\nthinking, particularly for scientists.\r\n<strong>Cognition and Creativity Revisited</strong>\r\nThe cognition (Kozbelt, Beghetto, &Runco, 2010) that gives\r\nrise to creative thinking is not a single process or operation\r\n(Smith & Ward, 1995), but rather consists of many different\r\ncognitive structures and processes that collaborate in a variety\r\nof ways to construct different types of creative output. There\r\nare two contrasting approaches to creativity in cognitive psychology. P. J. Guilford (Guilford, 1950) believed that creativity\r\ncan be measured in terms of divergent production, or the number of varied responses made to specific tests. Rather than one\r\ngood answer or single solution, divergent production results in\r\nmany possible ideas. However, sheer number of possible ideas\r\ndoes not guarantee that they are useful, high quality and novel.\r\nThe second approach is Sternberg and Lubartâ€™s investment\r\ntheory of creativity (Sternberg & Lubart, 1996). This theory\r\nstates that the appropriate attributes for creativity are knowledge, an encouraging environment, an appropriate personality,\r\nintelligence, motivation and an appropriate thinking style.\r\nStudies of creativity and cognition results (in terms of general intelligence) have found modest correlation between them\r\n(Silvia, 2008). Some researchers believe that creativity is the\r\noutcome of the same cognitive processes as intelligence, and\r\nonly judge creativity in terms of its consequences. Recent advances in neural science further show that general intelligence\r\nreflects the combined performance of brains systems (GlÃ¤scher\r\net al., 2010), but the brain is still a functional black box, in\r\nterms of how cognitive processes produce something novel.\r\nIn recent years, two approaches have dominated the research\r\nliterature on cognition-based creativity: process-oriented models of creativity, and systems-oriented models. Process-oriented\r\nmodels concentrate on cognitive aspects of creativity; while\r\nsystems-oriented models take a broader approach to creativity\r\ninvolving non-cognitive factors as well as cognitive ones. We\r\nsuggest a process-oriented model, which we suggest simulates\r\nhow the cognitive process relates to creativity.\r\n<strong>Framework of Mental Cognition</strong>\r\nWe firstly recall how cognition works, before it acts as a\r\nstimulus for creativity.\r\nWhen one thinks of Einstein, it is natural to assume that his\r\nbrain differed from that of the average person. In 1999, an anatomical study was made of Einstein\\\'s brain. Interestingly, his\r\nbrain was smaller than average. However, the study (Witelson\r\net al., 1999) also found that Einstein\\\'s parietal lobes were 15%\r\nwider than average. Science now points out that these lobes are\r\nusually connected to spatial and visual cognition, as well as to\r\nmathematics. Of course, the brain is a complex and\r\nstill-mysterious organ, but it may be that we can glean some\r\nadditional insight from this study: the relation of cognition to\r\ncreativity has a physiological basis.\r\nIn psychology, a cognitive process refers to how people\r\nperceive, remember, think, speak, and solve problems. The\r\ncognitive approach was brought to prominence by Donald\r\nBroadbent (Broadbent, 1958), who put forward an information\r\nprocessing model of cognition. This is a way of thinking and\r\nreasoning about mental processes, envisioning them as akin to\r\nsoftware running on a computer that is the brain. Theories refer\r\nto forms of input, representation, computation or processing,\r\nand outputs. Because of the use of computational metaphors\r\nand terminology, cognitive psychology was able to benefit\r\ngreatly from the flourishing of research in computer science.\r\nBased on such an information processing model of cognition,\r\nwe illustrate the cognition framework (Figure 1) using recent\r\nconceptual terms. The terms describe input sensations and perception, output behavior, intrinsic and learning cognition function units, and main memory. Memories (Atkinson & Shiffrin,\r\n1968) may be stored in long-term memory (LTM), short-term\r\nmemory (STM), autobiographical memory (ABM), and sensory\r\nmemory (SM).\r\nâ— SM. Sensory memory corresponds approximately to the\r\ninitial 200â€“500 milliseconds after an item is perceived. The\r\nability to look at an item, and remember what it looked like\r\nwithin just a second of observation, is an example of sensory\r\nmemory.\r\nâ— STM. Short-term memory allows recall for a period of several seconds to a minute without rehearsal. It provides the\r\nability to hold a small amount of information in mind in an\r\nactive, readily available state for a short period of time. The\r\nduration of short-term memory (when rehearsal or active\r\nmaintenance is prevented) is believed to be of the order of\r\nseconds. A commonly cited capacity is 7 Â± 2 stored items.\r\nâ— LTM. Long-term memory is memory in which associations\r\namong items are stored, according to the dual-store memory\r\nmodel (Atkinson and Shiffrin, 1968). Memories can reside\r\nin the short-term â€œbufferâ€ for a limited time while they are\r\nsimultaneously strengthening their associations in long-term\r\nmemory.\r\nâ— ABM. Autobiographical memory is a memory system consisting of episodes recollected from an individual\\\'s life,\r\nbased on a combination of episodic (personal experiences\r\nand specific objects, people and events experienced at particular time and place) and semantic (general knowledge and\r\nfacts about the world) memory (Williams, Conway, & Cohen, 2008).\r\nWe suggest a model to mental cognition using an analogy to\r\nthe Von Neumann architecture (Neumann, 1945) from computer\r\nscience. This model is not meant to be a serious suggestion of\r\nhow the brain works, but rather, a simplified description which\r\nis adequate for the purposes of discussing cognition and creativity.\r\nThe correspondences between mind and computer could be\r\ncan be considered to be: input devices to input sensory and\r\nperceptual organs, processor to intrinsic and learning cognition,\r\nmain memory to STM, disk to LTM, output devices to output\r\nmotor and behavior organs, input channels to SM and output\r\nchannels to ABM. See Figure 1.\r\nUsing this model, the mental cognitive process can be described as follows:\r\n1) The recognition and understanding of events, objects, and\r\nstimuli through the use of senses (sight, hearing, touch, etc.).\r\nSeveral different types of perception exist, and the data merged\r\nto give the input.\r\n2) The mind performs intrinsic cognition as primary\r\nprocessing of the input data, then more deeply operates on the\r\ndata using learned cognition.\r\n3) Operations are performed by retrieving stored information\r\nin response to cues, enable the information to be used in multiple processes or activities.\r\n4) Learned information is stored in the STM or LTM according to judgment, and if necessary, appropriate behaviors\r\nare output.\r\nClearly, our framework of mental cognition is a storedmemory model. The memory is the unit in which information is\r\nencoded, and stored, and from which it is retrieved. To sum up,\r\ninformation results from cognition of reality.\r\n<strong>Correlation between Cognition and Creativity</strong>\r\nThe correlation between cognition and creativity is an important problem in philosophy and psychology. We must consider the relationship, its origins and its forms, as well as the\r\nprinciples and laws of cognitive activity, and its development.\r\nAs a selective reflection of the world, cognition and filtering of\r\ninformation underpins human reasoning and drives human\r\nachievement. \r\nThere is much truth in the saying that in science the mind of\r\nthe scientist can build only as high as the foundations constructed by existing information will support. One of the research workerâ€™s duties is to follow the scientific literature, but\r\nlearning needs to be done with a critical, reflective attitude if\r\noriginality and freshness of outlook are not to be lost. Merely to\r\naccumulate information as a sort of capital investment is insufficient.\r\nIt is usual to carefully gather information dealing with the\r\nparticular problem on which one is going to work. However,\r\nsurprising as it may seem at first, some scientists consider that\r\nthis is unwise. They contend that investigating what others have\r\nsaid on the subject conditions the mind to see the problem in\r\nthe same way and make it difficult to find a new and fruitful\r\napproach. There are even some grounds for discouraging an\r\nexcessive amount of reading in the general field of science in\r\nwhich one is going to work. Many successful investigators\r\nwere not trained in the branch of science in which they made\r\ntheir most brilliant discoveries. But these researchers still had\r\nrelevant knowledge and were well trained. The same dilemma\r\nfaces all creative workers.\r\nWe may analyze this observation further. When a mind containing a wealth of information contemplates a problem, relevant information provides useful cues to the solution. It is advisable to make a thorough study of all the relevant literature\r\nearly in the investigation, for much effort may be wasted if\r\neven only one significant article is missed. However, if that\r\ninformation is insufficient, then the mass of this information\r\nmakes it more difficult for the mind to conjure up original ideas.\r\nFurther, some of that information maybe actually inappropriate,\r\nin which case it presents a more serious barrier to new and\r\nproductive ideas. During the course of an investigation, as well\r\nas watching for new papers on the problem, it is very useful to\r\nread more generally over a wide field keeping a constant watch\r\nfor some new principle or technique that may be useable. Often,\r\ntaking or adapting existing ideas from a different area is a key\r\nproblem solving step.\r\nThe best way of meeting the dilemma of â€œknowing too\r\nmuchâ€ is to critically obtain information, striving to maintain\r\nindependence of mind and avoid becoming conventionalized.\r\nFrancis Bacon said: â€œRead not to contradict and confute, nor to\r\nbelieve and take for grantedâ€¦but to weigh and considerâ€. The\r\nscientist with the right outlook for research develops a habit of\r\ncorrelating what is read with his knowledge, looking for significant analogies and generalizations.', '<strong>Simulation of Cognition and Creative Thinking</strong>\r\nIn his pioneering work Art of Thought, Wallas (Wallas, 1926)\r\npresented one of the first models of the creative process. In the\r\nWallas stage model, creative insights and illuminations may be thinking. Theories invoking divergent rather than convergent thinking (such as Guiford), or those describing the\r\nstaging of the creative process (such as Wallas) are primarily theories of creative process. J. P. Guilford (Guiford,\r\n1967) performed important work in the field of creativity,\r\ndrawing a distinction between convergent and divergent\r\nproduction or thinking. Convergent thinking involves aiming at a single, correct solution to a problem, whereas divergent thinking involves creatively generating multiple\r\nanswers to a problem. Divergent thinking is sometimes used\r\nas a synonym for creativity in the psychology literature. Intrinsic, task-focused motivation is also essential to creativity.\r\nâ— Verification. After verifying, elaborating, and applying the\r\ncreative idea using similarity, a creative (original and\r\nworthwhile) result is produced.\r\nNote that the main characters of this model are the simulation\r\nfactors, which are seamlessly integrated into the mechanical\r\nanalysis of cognition and creativity. By using the computer\r\nsimulation units, we provide a foundation to simulate the abstract mental model of cognition and creativity. The simulation\r\ncould be performed by finding analytical solutions to cognition-based creative thinking problems, which enables the recording, verification, and even prediction of the behavior of the\r\ncognition-based creativity from a set of parameters and initial\r\nconditions. Furthermore, by concurrently performing simulation and real cognition and creativity tasks, our new framework\r\ncan effectively deal with the interplay between experiment,\r\nsimulation, and theory for the cognition and creativity correlation investigation.\r\nOur work continues in the tradition of others (e.g. (Graham-Rowe, 2005)) in asserting that creativity is a balance of\r\nimagination and analysis by using information. The simulation\r\nmodel also purposefully avoids taking a stand on the controversy of whether creativity is a conscious or subconscious cognitive result. While we personally believe that intrinsic motivation is a conscious, non-magical mental action, the activity of\r\nâ€œproducing creative resultsâ€ in the model accepts creative ideas\r\nregardless of their source. Finally, note that this model clearly\r\nsupports the notion that creativity is a step beyond the simple\r\nrecognition of reality. The simulation model has value only\r\nwhen it is implemented in the real world.\r\nexplained by a process comprising 5 stages:\r\n1) Preparation. The scientist focus his mind on the problem\r\nand explores the problemâ€™s dimensions;\r\n2) Incubation. The problem is internalized into the unconscious mind and nothing appears externally to be happening;\r\n3) Intimation. The creative person gets a feeling that a solution is on its way;\r\n4) Illumination or insight. The creative idea bursts forth\r\nfrom its preconscious processing into conscious awareness;\r\n5) Verification. The idea is consciously verified, elaborated,\r\nand then applied.\r\nWallasâ€™ model is often treated as four stages, with intimation\r\nseen as a sub-stage. Wallas considered creativity to be a legacy\r\nof the evolutionary process, which allowed humans to quickly\r\nadapt to rapidly changing environments. The implied theory\r\nbehind Wallasâ€™ modelâ€“that creative thinking is a subconscious\r\nprocess that cannot be directed, and that creative and analytical\r\nthinking are complementaryâ€“is reflected to varying degrees in\r\nother models of creativity. In contrast to the prominent role that\r\nsome models give to subconscious processes, Perkins (Perkins,\r\n1981) argues that subconscious mental processes are behind all\r\nthinking and, therefore, play no extraordinary role in creative\r\nthinking. (Ram et al., 1995) proposed the five components for\r\ncreativity: inferential mechanisms, knowledge sources, tasks,\r\nsituation, and strategic control.\r\nWhile there are many models for the process of creative\r\nthinking, it is not difficult to see consistent themes that span\r\nthem all. 1) The creative process involves purposeful analysis,\r\nimaginative idea generation, and critical evaluationâ€“the overall\r\ncreative process is a balance of imagination and analysis. 2)\r\nOlder models tend to imply that creative ideas result from subconscious processes, largely outside the control of the thinker.\r\nModern models tend to imply purposeful generation of new\r\nideas, under the direct control of the thinker. 3) The overall\r\ncreative process requires a drive to action and the implementation of ideas. We must do more than simply imagine new things,\r\nwe must work to make them concrete realities.\r\nThese insights from a review of the many models of creative\r\nthinking have encouraged us to produce a synthetic simulation\r\nmodel (Humphreys, 2004) of creative thinking that combines\r\nthe concepts behind the various models proposed over the last\r\nyears.(Figure 2)\r\nOur model has three main components as follows:\r\nâ— Recognition. Recognition uses memories storing information\r\nin SM, STM, and LTM, sensing and learning functional organs, and cognition processors.\r\nâ— Creativity. Creativity units (including creative thinking mechanisms) and skills (creativity mapping) work together to\r\nproduce novel and useful produces (Mumford, 2003). The\r\ndominant factors are usually identified as \\\"the four\r\nPs\\\"â€“process, product, person and place (Kozbelt, 2010). A\r\nfocus on process is shown in cognitive approaches that try to\r\ndescribe thought mechanisms and techniques for creative', '<strong>Creative Thinking Enlightenment</strong>\r\nAs it is still impossible to physically record the mental cognition and creativity process, we use our former model to simulate the functionalities of learning and thinking. In the section,\r\nwe first review thinking, and discuss why visual analogical\r\nthinking is an appropriate choice for enlightening creative\r\nthinking. We then consider an example from computer graphics\r\nof automatic 3D model creation.\r\n<strong>Thinking Mechanism Review</strong>\r\nReasoning, visual thinking, intuition and inspiration are\r\nstanding thinking mechanisms. In the following, we discuss\r\nwhich can be learned and are applicable for a scientist performing creative research.\r\nThe origin of creativity is somewhat beyond the reach of\r\nlogical reasoning (Aldo, 2003). The role of logical reasoning in\r\nresearch is not in making discoveries (either factual or theoretical), but verifying, interpreting and developing them and\r\nbuilding a general theoretical scheme. Most scientific facts and\r\ntheories are only true under certain conditions and our knowledge is so incomplete that at best we can only reason based on\r\nprobabilities and possibilities. Besides logical reasoning, analogical reasoning is a mutually exclusive alternative for the\r\nthinking. Analogs are achieved by a comparison that determines the degree of similarity, or an inference based on resemblance or correspondence. As we know, while results from an\r\nanalogy may or may not be true, analogical thinking can produce new ideas.\r\nVisual thinking, or right brained thinking, is the common\r\nphenomenon of thinking through visual processing using the\r\npart of the brain that is emotional and creative to organize information in an intuitive and simultaneous way. During his\r\nlifetime, Einstein often claimed that he thought in images and\r\nsensations rather than in words.\r\nIntuition and inspiration indicate a sudden enlightenment or\r\ncomprehension of a situation, a clarifying idea which dramatically springs into the consciousness, often, though not necessarily, when one scientist is not consciously thinking of special\r\nsubject. The most characteristic circumstances of an intuition\r\nare a period of intense work on the subject accompanied by a\r\ndesire for its solution, followed by the appearance of the creative idea with dramatic suddenness and often a sense of certainty. Intuition is still a mystical issue, and we are a long way\r\nfrom really understanding and simulate it.\r\nTheobald Smithâ€™s said that: â€œDiscovery should come as an\r\nadventure rather than as the result of a logical process of\r\nthought. Sharp, prolonged thinking is necessary that we may\r\nkeep on the chosen road, but it does not necessarily lead to\r\ndiscoveryâ€. As we know, all scientific advances rest on a base\r\nof previous knowledge. Often, the application or transfer of a\r\nnew principle or technique from another field provides the central idea upon which an investigation hinges. Such transfer is a\r\ntypical analogical thinking scheme. In attempting to apply an\r\nexisting technique to a new problem, some new knowledge\r\narises.\r\nIn the process of creativity, it is not the knowledge (information) stored which is so important as the scientist making use of\r\nknowledge. During scientific creative thinking, analogical and\r\nvisual thinking are both learnable and applicable tactics.\r\n<strong>New 3D Model Creation</strong>\r\n3D modeling is the process of developing a mathematical representation of any three-dimensional object, called a â€œ3D\r\nmodelâ€. It is one of the most fundamental tasks in computer\r\ngraphics. We demonstrate how analogical and visual thinking\r\ntactics may be employed within a computer program to automatically creatively generate novel 3D models.\r\nCreating a 3D model of modest complexity is typically a\r\ndaunting task, so a sensible strategy is to generate a novel shape\r\nas a variation of one or more existing models. In a typical paper\r\n(Xu et al., 2010), new shapes are synthesized replicating a certain style extracted from a set of input shapes. The particular\r\nstyle studied is the anisotropic scaling of the shape parts. The\r\nkey enabling concept is style-content separation which facilitates the computation of part correspondence across a whole set\r\nof input shapes exhibiting large style variations. Style-content\r\nseparation then allows style transfer as a basis for synthesis of\r\nnew objects. Figure 3 show the style-content separation\r\nprocess and automatic 3D model creation. Our idea is a typical\r\nexample of the use of analogical thinking, this time performed the computer, to create different styles of model. Using the\r\ntransfer rule, some newly-created models do not meet or requirements and expectations. This shows that when concepts\r\nare transferred to another area, they are often instrumental in\r\nuncovering still further knowledge. The example gives some\r\nhints on how best to go about various activities that constitute\r\nresearch, but explicit rules can not be laid out since research is\r\nan investigatory art.\r\nThe possibility of developments in the transfer method is\r\nperhaps the main reason why the scientist needs to keep himself\r\ninformed of at least the principal developments taking place in\r\nmore than his own narrow field of work.', 'A scientist works like a pioneer as he explores the frontier of\r\nknowledge, and requires many of the same attributes: enterprise\r\nand initiative, readiness to face difficulties and overcome them\r\nwith his own resourcefulness and ingenuity, perseverance, a\r\nspirit of adventure, a certain dissatisfaction with well-known\r\nterritory and prevailing ideas, and an eagerness to try his own\r\njudgment. What is produced can come in many forms and is not\r\nspecifically singled out in a subject or area.\r\nIn this paper, we have tried to suggest how cognition works\r\nfor creative thinking, which is more important than the 99%\r\nperspiration. We have tried to solve the problem by using exemplars from computer science. Firstly, we have made use of\r\ncomputer simulation to investigate the correlation between\r\ncognition and creative thinking. Then, the 3D model creation in\r\ncomputer graphics is used as an illustration to explain why the\r\nanalogical and visual thinking are enlightening for creative\r\nthinking.\r\nIt is probably inevitable that any paper which attempts to\r\ndeal with such a wide and complex subject will have many\r\nlimitations. We hope the shortcomings of our work may provoke others whose achievements and experience are greater\r\nthan ours to write about this subject and so build up a greater\r\nbody of organ', 'De Bono, E. (2008). How to have creative idea: 62 games to develop\r\nthe mind. Publisher: Vermilion.\r\nBernard, C. (1865). An introduction to the study of experimental medicine (English translation). Macmillan & co. New York, 1927.\r\nGuilford, J. P. (1950). Creativity. American Psychologist, 5(9),\r\n444-454.\r\nSternberg, R. J., & Lubart, T. I. (1996). Investing in creativity. American Psychologist, 51(7), 677-688.\r\nSilvia, P. J. (2008). Creativity and intelligence revisited: A reanalysis of\r\nWallach and Kogan (1965). Creativity Research Journal, 20, 34-39.\r\nGlÃ¤scher J., Rudrauf D., Colom R., Paul L. Tranel K., D., Damasio H.,\r\n& Adolphs R. (2010). The distributed neural system for general intelligence revealed by lesion mapping. In Proceedings of the National Academy of Sciences.\r\nWitelson S. F., Kigar D. L., & Harvey T. (1999). The exceptional brain\r\nof Albert Einstein. Lancet, 353, 2149-2153.\r\nBroadbent, D. E. (1987). Perception and communication. Oxford: Oxford University Press.\r\nvon Neumann, J. (1945). First Draft of a Report on the EDVAC.\r\nMooney G. A., Fewtrell R. F., & Bligh J. G. (1999). Cognitive process\r\nmodelling: computer tools for creative thinking and managing learning. Medical Teacher, 21(3), 277-280\r\nWallas, G. (1926). Art of Thought.\r\nPerkins, DN (1981) The Mind\\\'s Best Work. Cambridge, MA: Harvard\r\nUniversity Press.\r\nRam A., Wills L., Domeshek E., Nersessian N., &Kolodner J.(1995).\r\nUnderstanding the Creative Mind. AI Journal, 79, 111-128.\r\nSternberg, R.J. (2006). The Nature of Creativity. Creativity Research\r\nJournal, 18(1), 87-98.\r\nGabora, L. (2002). Cognitive mechanisms underlying the creative\r\nprocess. Proceedings of the Fourth International Conference on\r\nCreativity and Cognition (pp. 126-133), UK.\r\nMumford, M. D. (2003). Where have we been, where are we going?\r\nTaking stock in creativity research. Creativity Research Journal, 15,\r\n107-120.\r\nKozbelt, A., Beghetto, R. A. & Runco, M. A. (2010). Theories of Creativity. The Cambridge Handbook of Creativity. Cambridge University Press', 'Creative Thinking; Enlightenment; Cognition; Computer Graphics, Computer Simulation', 'Williams, H. L., Conway, M. A., & Cohen, G. (2008). Autobiographical memory. Memory in the Real World (3rd ed., pp. 21-90). Hove,\r\nUK: Psychology Press.\r\nAtkinson, R.C.; Shiffrin, R.M. (1968). Human memory: A proposed\r\nsystem and its control processes. In Proceedings of The psychology\r\nof learning and motivation (2, pp. 89-195). New York: Academic\r\nPress.\r\nHumphreys P. (2004). Extending Ourselves: Computational Science,\r\nEmpiricism, and Scientific Method. Oxford: Oxford University Press.\r\nGraham-Rowe, D. (2005). Mission to build a simulated brain begins.\r\nNewScientist.\r\nAldo A., Lex W., & Ganter B.. (2003) Conceptual Structures for\r\nKnowledge Creation and Communication, LNAI 2746, 16-36.\r\nXu K., Li H., Zhang H., Cohen-Or D., Xiong Y., & Cheng Z.-Q. (2010).\r\nStyle-Content Separation by Anisotropic Part Scales. ACM Transactions on Graphics, 29(6), 184:1-184:10.\r\nBermÃºdez. J. L. (2010). Cognitive Science: An Introduction to the\r\nScience of the Mind. Publisher: Cambridge University Press.', '64dd10f028f8b.jpg');

-- --------------------------------------------------------

--
-- Table structure for table `team`
--

CREATE TABLE `team` (
  `id_profile` int(11) NOT NULL,
  `title` varchar(500) NOT NULL,
  `team_position` varchar(50) NOT NULL,
  `position` varchar(200) NOT NULL,
  `university` varchar(200) NOT NULL,
  `email` varchar(200) NOT NULL,
  `tel` varchar(200) NOT NULL,
  `fax` varchar(200) NOT NULL,
  `room` varchar(200) NOT NULL,
  `city` varchar(200) NOT NULL,
  `research_cluster` varchar(500) NOT NULL,
  `research_interest` varchar(500) NOT NULL,
  `interests` varchar(500) NOT NULL,
  `academic_qualification` varchar(500) NOT NULL,
  `small_image` varchar(200) NOT NULL,
  `big_image` varchar(200) NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

--
-- Dumping data for table `team`
--

INSERT INTO `team` (`id_profile`, `title`, `team_position`, `position`, `university`, `email`, `tel`, `fax`, `room`, `city`, `research_cluster`, `research_interest`, `interests`, `academic_qualification`, `small_image`, `big_image`) VALUES
(1, 'PUTRA SUMARI, PROFESSOR DR.', 'Head', 'Professor', 'School of Computer Sciences, Universiti Sains Malaysia, 11800 USM, Pulau Pinang', 'Email : putras@usm.my', '+604 653 3615', '+604 653 3335', '721', 'Pulau Pinang, Malaysia', 'Service Computing', 'Image & video retrival, Brain computer interface, Watermarking, Compression, Video on demand system', 'My research interest lie on image and videoa analysis for medical, video on demand system, watermaking and compression applications.  I am also interested on the use of brain signals for computer application.     ', 'I am professor in the school of computer science at the university of science, malaysia. I received msc in 1996 at liverpool university and phd in 2001 at john moores university, england. Both are in computer sciences specifically in software engineering and video processing respectively. I have been a visiting fellow at department of computer sciences at national univerasity of singapore from 2006 to 2008.', '<p><img src=\"assets/img/team/putra_small.jpg\" alt=\"\"class=\'img-fluid rounded-circle\'></p>', '<p><img src=\"assets/img/team/putrabig.jpg\" alt=\"\"class=\'img-fluid\'></p>'),
(2, 'NUR INTAN RAIHANA RUHAIYEM, DR.', 'Secretary', 'SENIOR LECTURER', 'School of Computer Sciences, Universiti Sains Malaysia, 11800 USM, Pulau Pinang', 'intanraihana@usm.my', '+604 653 4387', '+604 653 3335', '528', 'Pulau Pinang', 'Data To Knowledge', 'Image Processing for Medical Data, Data Visualisation and Computer Vision', 'Medical Imaging, Healthcare Data Management and Visualisation, Deep Learning of Image Data.', '<li>PhD., University of Queensland, Australia, 2014</li><li>MSc. (Computer Science), Universiti Sains Malaysia, Malaysia, 2008 </li><li>BMM (Hons), Universiti Utara Malaysia, Malaysia, 2006</li><li>BSc. Mathematics (Hons), Universiti Sains Malaysia, 2022</li>', '<p><img src=\"assets/img/team/intan_small.jpg\" alt=\"\"class=\'img-fluid rounded-circle\'></p>\r\n', '<p><img src=\"assets/img/team/intanbig.jpg\" alt=\"\"class=\'img-fluid\'></p>\r\n'),
(3, 'MOHD NADHIR AB WAHAB, DR.\r\n', 'Comittee', 'SENIOR LECTURER', 'School of Computer Sciences, Universiti Sains Malaysia, 11800 USM, Pulau Pinang', 'mohdnadhir@usm.my', '+604 653 2320', '+604 653 3335', '525', 'Pulau Pinang, Malaysia', 'Data To Knowledge', 'Artificial Intelligence, Computational Intelligence, Computer Vision, Machine Learning, Mobile. Robotics, Optimization, Path Planning.', 'My research is in the fields of Artificial Intelligence, Computer Vision, Machine Learning, Path Planning, and Robotics. Currently, I am focusing on applications in Machine Learning, Deep Learning, Computer Vision, Path Planning, and Mobile Robotics. ', '<li>B.Eng. (Hons.), UniMAP, Malaysia</li> <li>M.Sc., UniMAP, Malaysia</li> <li>Ph.D., University of Salford, United Kingdom </li>', '\r\n<p><img src=\"assets/img/team/nadhir_small.jpg\" alt=\"\"class=\'img-fluid rounded-circle\'></p>', '\r\n<p><img src=\"assets/img/team/nadhirbig.jpg\" alt=\"\"class=\'img-fluid\'></p>'),
(4, 'MOHD HALIM MOHD NOOR, DR.', 'Comittee', 'SENIOR LECTURER', 'School of Computer Sciences, Universiti Sains Malaysia, 11800 USM, Pulau Pinang', 'halimnoor@usm.my', '+604 653 4757', '+604 653 3335', '610', 'Pulau Pinang, Malaysia', 'Data To Knowledge', 'Machine learning and deep learning for computer vision and pervasive computing.', 'My research is in the fields of machine learning and deep learning for computer vision and pervasive computing. Currently I am focusing on problems in human activity recognition and medical image analysis such as segmentation, feature learning, and prediction.', '<li>BEng, IIUM, Malaysia.</li><li>MSc, USM, Malaysia.</li><li>PhD, University of Auckland, New Zealand.</li>', '<p><img src=\"assets/img/team/halim_small.jpg\" alt=\"\"class=\'img-fluid rounded-circle\'></p>\r\n', '<p><img src=\"assets/img/team/halimbig.jpg\" alt=\"\"class=\'img-fluid\'></p>\r\n'),
(5, 'AHMAD SUFRIL AZLAN MOHAMED,DR.', 'Comittee', ' ASSOCIATE PROFESSOR', 'Universiti Sains Malaysia', ' sufril@usm.my', '+604 653 6351', '+604 653 3335', '520', 'Pulau Pinang, Malaysia', 'Data to Knowledge', 'Image Processing, Video Tracking, Facial Recognition and Medical Imagin', 'Industrial Design, Bioresource, Paper and Coatings Technology, Laser', '<li>BIT (Hons), Multimedia University, Malaysia, 2003</li>              <li>MSc., University of Manchester, United Kingdom, 2005</li>              <li>PhD., University of Salford, United Kingdom, 2015.</li>', '<p><img src=\"assets/img/team/sufril_small.jpg\" alt=\"\"class=\'img-fluid rounded-circle\'></p>', '<p><img src=\"assets/img/team/sufrilbig.jpg\" alt=\"\"class=\'img-fluid\'></p>');

--
-- Indexes for dumped tables
--

--
-- Indexes for table `login`
--
ALTER TABLE `login`
  ADD PRIMARY KEY (`id_user`);

--
-- Indexes for table `project`
--
ALTER TABLE `project`
  ADD PRIMARY KEY (`id_project`);

--
-- Indexes for table `team`
--
ALTER TABLE `team`
  ADD PRIMARY KEY (`id_profile`);

--
-- AUTO_INCREMENT for dumped tables
--

--
-- AUTO_INCREMENT for table `login`
--
ALTER TABLE `login`
  MODIFY `id_user` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=10;

--
-- AUTO_INCREMENT for table `project`
--
ALTER TABLE `project`
  MODIFY `id_project` int(50) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=105;

--
-- AUTO_INCREMENT for table `team`
--
ALTER TABLE `team`
  MODIFY `id_profile` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=7;
COMMIT;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
